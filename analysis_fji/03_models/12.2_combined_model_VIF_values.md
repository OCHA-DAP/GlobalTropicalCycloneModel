```python
import os
from pathlib import Path
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from xgboost.sklearn import XGBRegressor
import matplotlib.pyplot as plt
import seaborn as sns
from utils import get_combined_dataset_interpolated_with_viet_new_bld_count_using_pop, get_training_dataset_phl
```

## Load data


```python
# Load combined dataset interpolated
df_combined_with_viet = get_combined_dataset_interpolated_with_viet_new_bld_count_using_pop()
df_fji_with_viet = df_combined_with_viet[df_combined_with_viet.country == 'fji']
```

## Define model


```python
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

def xgb_model_LOOCV(df_combined, df_fji, features, fji_weight, phl_weight=1, viet_weight=1):
    # Dataframe Fiji
    fji_typhoons = df_fji.typhoon_name.unique()

    y_test_typhoon_fji  = []
    y_pred_typhoon_fji  = []
    correlation_matrix = pd.DataFrame()

    for typhoon in fji_typhoons:

        """ PART 1: Train/Test """

        # LOOCV
        df_test = df_fji[df_fji["typhoon_name"] == typhoon] # Test set: Fiji
        df_train = df_combined[df_combined["typhoon_name"] != typhoon] # Train set: everything

        # Class weight
        weights = np.select(
            [
                (df_train['country'] == 'phl'),
                (df_train['country'] == 'viet'),
                (df_train['country'] == 'fji')
            ],
            [
                phl_weight,
                viet_weight,
                fji_weight
            ],
            default=1
        )

        # Split X and y from dataframe features
        X_test = df_test[features]
        X_train = df_train[features]

        y_train = df_train["percent_houses_damaged"]
        y_test = df_test["percent_houses_damaged"]


        """ PART 2: XGB regressor """
        # create an XGBoost Regressor
        xgb = XGBRegressor(
            base_score=0.5,
            booster="gbtree",
            colsample_bylevel=0.8,
            colsample_bynode=0.8,
            colsample_bytree=0.8,
            gamma=3,
            eta=0.01,
            importance_type="gain",
            learning_rate=0.1,
            max_delta_step=0,
            max_depth=4,
            min_child_weight=1,
            missing=1,
            n_estimators=100,
            early_stopping_rounds=10,
            n_jobs=1,
            nthread=None,
            objective="reg:squarederror",
            reg_alpha=0,
            reg_lambda=1,
            scale_pos_weight=1,
            seed=None,
            silent=None,
            subsample=0.8,
            verbosity=0,
            eval_metric=["rmse", "logloss"],
            random_state=0,
        )

        # Fit the model
        eval_set = [(X_train, y_train)]
        xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False, sample_weight=weights) #xgb_model

        # Calculate correlation matrix
        #corr_matrix = X_train.corr()
        corr_matrix = df_train[features + ['percent_houses_damaged']].rename({'percent_houses_damaged':'target_variable'}, axis=1).corr()

        # Append y_train as a column
        corr_matrix['typhoon_name'] = typhoon
        correlation_matrix = pd.concat([correlation_matrix, corr_matrix])

        # make predictions on Fiji
        y_pred_fji = xgb.predict(X_test)

        # Save y_test y_pred
        y_test_typhoon_fji.append(y_test)
        y_pred_typhoon_fji.append(y_pred_fji)


    return y_test_typhoon_fji, y_pred_typhoon_fji, correlation_matrix
```

## Run model and compute Correlation Matrix for each event


```python
# Features
features= [
    "wind_speed",
    "track_distance",
    "total_houses",
    "rainfall_max_6h",
    "rainfall_max_24h",
    "coast_length",
    "with_coast",
    "mean_elev",
    "mean_slope",
    "IWI"
]
```


```python
# Fji + Phl + Viet (with IWI)
y_test_typhoon_fji, y_pred_typhoon_fji, corr_matrix = xgb_model_LOOCV(
    df_combined=df_combined_with_viet,
    df_fji=df_fji_with_viet,
    fji_weight=4,
    phl_weight=1,
    features=features
)
```

## mean correlation values


```python
typhoons = corr_matrix.typhoon_name.unique()
list_matrices = []
for typhoon in typhoons:
    corr_event = corr_matrix[corr_matrix.typhoon_name==typhoon].drop('typhoon_name', axis=1).to_numpy()
    list_matrices.append(corr_event)
```


```python
# Stack the matrices along a new axis
stacked_matrices = np.stack(list_matrices, axis=0)

# Compute the mean along the new axis
mean_matrix = np.mean(stacked_matrices, axis=0)

# Create a DataFrame with the mean matrix
mean_df = pd.DataFrame(mean_matrix, index=corr_matrix.drop('typhoon_name', axis=1).columns, columns=corr_matrix.drop('typhoon_name', axis=1).columns)
```


```python
# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(mean_df, dtype=bool))

# Plot the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(mean_df, cmap='coolwarm', annot=True, fmt=".2f", mask=mask)
plt.title('Mean Correlation Matrix')
plt.show()
```



![png](12.2_combined_model_VIF_values_files/12.2_combined_model_VIF_values_11_0.png)
