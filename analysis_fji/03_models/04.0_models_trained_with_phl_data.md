---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: env1
    language: python
    name: python3
---

```python
import statistics

from sklearn import preprocessing
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from xgboost.sklearn import XGBRegressor
from xgboost import XGBClassifier
from sklearn.dummy import DummyRegressor
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import statsmodels.api as sm

from utils import get_training_dataset_complete, get_training_dataset_phl
```

## Data cleaning and stratification

```python
# Fiji
df_complete = get_training_dataset_complete()
df_fji= df_complete.rename({'perc_dmg_grid':'percent_houses_damaged', 'total_buildings':'total_houses', 'mean_altitude':'mean_elev'}, axis=1)
```

```python
# Philippines
df_phl = get_training_dataset_phl()
df = df_phl.copy()
```

```python
print(df.columns)
```

```python
# Set any values of damage houses >100% to 100% .. ok
for r in range(len(df)):
    if df.loc[r, "percent_houses_damaged"] > 100:
        df.at[r, "percent_houses_damaged"] = float(100)
```

```python
#drop windspeed = 0
df = (df[(df[["wind_speed"]] != 0).any(axis=1)]).reset_index(drop=True)

#drop some other not relevant columns
df = df.drop(columns=["grid_point_id", "typhoon_year"])
```

## Stratification


### Some plots just to see

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))

ax[0].hist(df.percent_houses_damaged, edgecolor='black')
ax[0].set_xlabel('% Houses Damaged',size=15)
ax[0].set_ylabel('Frequency',size=15)

hist = np.histogram(df.percent_houses_damaged, bins=10 ** np.linspace(0, np.log10(10**2.1), len(df)), density=True)
x = hist[1][:-1]
y = hist[0]

ax[1].plot(x,y, 'ro', alpha=0.4, label='housing damage')
ax[1].set_xscale('log')
ax[1].set_yscale('log')
ax[1].set_xlabel('% Houses Damaged', size=15)
ax[1].set_ylabel('Frequency', size=15) #PDF (% Houses Damaged)
ax[1].grid(c='black', alpha=0.3)
ax[1].legend()

plt.tight_layout()
plt.show()
```

```python
#Lets see how the distribution of damage is as a function of the total information
dmg = np.array(df.percent_houses_damaged.to_list())
offset = 1e-8
dmg_off = dmg + offset
x = list(np.linspace(0,1,101))
info = []
for i in x:
    info.append(np.quantile(dmg_off, i))

plt.plot(x,info,'o')
plt.xlabel('Quantile')
plt.ylabel('Damage [%]')
plt.yscale('log')
plt.title('Damage Offset = {}'.format(offset))
plt.grid()
plt.show()
```

### Actual stratification for Philippines

```python
# We are going to use same stratification bins that were used in the Philippines project

bins = [0, 0.00009, 1, 10, 50, 101]
samples_per_bin, bins_def = np.histogram(df["percent_houses_damaged"], bins=bins)
print(samples_per_bin)

num_bins = len(bins)-1
# For future plots
str_bin = []
for i in range(len(bins_def[:-1])):
    a = str(np.round(bins_def[i+1],3))
    b = str(np.round(bins_def[i],3))
    str_bin.append('{} - {}'.format(b,a))
str_bin
```

### Actual stratification for Fiji

```python
# Stratification
dmg = np.array(df_fji.percent_houses_damaged.to_list())
zero_dmg = np.round((np.count_nonzero(dmg == 0) / len(dmg)) , 2 )

# Define ranges for each group
x0 = list(np.linspace(0, zero_dmg, 1))   # zero damage
x1 = list(np.linspace(zero_dmg, 0.93, 2))  # almost no damage
x2 = list(np.linspace(0.935, 1, 5))  # all the damage
x3=x0+x1+x2

bins = []
for i in x3:
    bins.append(np.quantile(dmg, i))

# Histogram after stratification
samples_per_bin_fji, bins_def_fji = np.histogram(dmg, bins=bins)
print(samples_per_bin_fji)

# Define number of bins
num_bins_fji = len(samples_per_bin_fji)

# For future plots
str_bin_fji = []
for i in range(len(bins_def_fji[:-1])):
    a = str(np.round(bins_def_fji[i+1],3))
    b = str(np.round(bins_def_fji[i],3))
    str_bin_fji.append('{} - {}'.format(b,a))
print(str_bin_fji)
```

## Model for Fiji, trained on Fiji subset

```python
from xgboost.sklearn import XGBRegressor
rmse_xgb = []
rmse_bin_xgb = []
avg_error_bin_xgb = []

y_test_typhoon_xgb  = []
y_pred_typhoon_xgb  = []

# List of typhoons
typhoons_fji = df_fji.typhoon_name.unique()

# Specify features
features_fji = [
    "wind_speed",
    "track_distance",
    "total_houses",
    "rainfall_max_6h",
    "rainfall_max_24h",
    "coast_length",
    "with_coast",
    "mean_elev",
    "mean_slope",
    #"IWI"
]

for typhoon in typhoons_fji:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df_fji[features_fji]
    y = df_fji["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df_fji[df_fji["typhoon_name"] == typhoon]
    df_train = df_fji[df_fji["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features_fji]
    X_train = df_train[features_fji]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def_fji[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def_fji[:-1])

    """ PART 2: Linear regressor """
    # create an XGBoost Regressor
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )


    # fit it on the training set
    eval_set = [(X_train, y_train)]
    xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False) #xgb_model

    # make predictions on the test set
    y_pred = xgb.predict(X_test)
    # make predictions on the train set
    y_pred_train = xgb.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon_xgb.append(y_test)
    y_pred_typhoon_xgb.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_xgb.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin_xgb = []
    avg_error_test_bin_xgb = []
    for bin_num in range(num_bins_fji+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin_xgb.append(rmse_test)
            # Avg error
            mean_difference = np.mean(y_test[bin_index_test == bin_num] - y_pred[bin_index_test == bin_num])
            avg_error_test_bin_xgb.append(mean_difference)
        else:
            rmse_test_bin_xgb.append(np.nan)
            avg_error_test_bin_xgb.append(np.nan)
    rmse_bin_xgb.append(rmse_test_bin_xgb)
    avg_error_bin_xgb.append(avg_error_test_bin_xgb)
```

```python
rmse_strat_xgb = []
avg_error_strat_xgb = []
for i in range(num_bins_fji):
    #RMSE
    test_rmse_bin = np.nanmean(np.array(rmse_bin_xgb)[:,i])
    rmse_strat_xgb.append(test_rmse_bin)
    #AVG error
    test_avg_bin = np.nanmean(np.array(avg_error_bin_xgb)[:,i])
    avg_error_strat_xgb.append(test_avg_bin)
```

```python
fig, ax = plt.subplots(1,1, figsize=(6,6))
ax.plot(range(num_bins_fji), rmse_strat_xgb, 'bs')
ax.set_xticks(range(num_bins_fji), str_bin_fji, rotation=45)
ax.set_xlabel('Damage [%]')
ax.set_ylabel('RMSE')
ax.grid()

# ax[1].plot(range(num_bins_fji), avg_error_strat_xgb, 'bs')
# ax[1].set_xticks(range(num_bins_fji), str_bin, rotation=45)
# ax[1].set_xlabel('Damage [%]')
# ax[1].set_ylabel('Avg error ')
# ax[1].grid()

plt.suptitle('XGBoost Regression model')
plt.tight_layout()
plt.show()
```

## Models for the Philippines dataset

```python
# List of typhoons
typhoons = df.typhoon_name.unique()

# Specify features that we have in both datasets
features = [
    "wind_speed",
    "track_distance",
    "total_houses",
    "rainfall_max_6h",
    "rainfall_max_24h",
    "coast_length",
    "with_coast",
    "mean_elev",
    "mean_slope",
    #"IWI"
]
```

### Baseline dummy model

```python
rmse_dummy = []
rmse_bin_dummy = []

y_test_typhoon = []
y_pred_typhoon = []

for typhoon in typhoons:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def[:-1])

    """ PART 2: Dummy regressor """
    # create a dummy regressor
    dummy_reg = DummyRegressor(strategy="mean")

    # fit it on the training set
    dummy_reg.fit(X_train, y_train)

    # make predictions on the test set
    y_pred = dummy_reg.predict(X_test)
    # make predictions on the train set
    y_pred_train = dummy_reg.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon.append(y_test)
    y_pred_typhoon.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_dummy.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin.append(rmse_test)
        else:
            rmse_test_bin.append(np.nan)

    rmse_bin_dummy.append(rmse_test_bin)
```

#### Dummy model results

```python
#total RMSE
print('dummy_mean_RMSE_total: ', np.nanmean(rmse_dummy))
```

```python
rmse_strat_dummy = []
for i in range(num_bins):
    dummy_test_rmse_bin = np.nanmean(np.array(rmse_bin_dummy)[:,i])
    rmse_strat_dummy.append(dummy_test_rmse_bin)
#rmse_strat_dummy
```

```python
plt.plot(range(num_bins), rmse_strat_dummy, 'bs')
plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('Baseline model')
plt.grid()
plt.show()
```

### 2SG-XGB

```python
thres = 10 # Damage threshold
df[df.percent_houses_damaged >= thres]
```

```python
rmse_combined = []
rmse_bin_combined = []

y_test_typhoon_combined = []
y_pred_typhoon_combined = []

# Also, let's save the models we're using for make predictions later!
M1_models = []
high_damage_models = []
classification_models = []

i=0
for typhoon in typhoons:

    """      STEP 0: TRAIN TEST SPLIT      """

    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    print('{}/{} '.format(i+1, len(typhoons)),typhoon)
    i+=1

    """      STEP 1: M-model (510 model)      """

    # XGBoost Reduced Overfitting
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )

    eval_set = [(X_train, y_train)]
    xgb_model = xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)

    M1_models.append(xgb_model)

    # Make prediction on train and test data
    y_pred_train = xgb.predict(X_train)
    y_pred = xgb.predict(X_test)

    # Calculate RMSE in total
    mse_train_idx = mean_squared_error(y_train, y_pred_train)
    rmse_train = np.sqrt(mse_train_idx)

    mse_idx = mean_squared_error(y_test, y_pred)
    rmseM1 = np.sqrt(mse_idx)

    """      STEP 2: 2SG-Model part 1, Classifier      """

    # Define a threshold to separate target into damaged and not_damaged
    y_test_bool = y_test >= thres
    y_train_bool = y_train >= thres
    y_test_bin = (y_test_bool) * 1 #nice way to concert boolean to binary
    y_train_bin = (y_train_bool) * 1


    # Use XGBClassifier as a Machine Learning model to fit the data
    xgb_model = XGBClassifier(eval_metric=["error", "logloss"])
    eval_set = [(X_test, y_test_bin)]
    xgb_model.fit(X_train,y_train_bin,eval_set=eval_set,verbose=False)

    classification_models.append(xgb_model)

    # Make prediction on test data
    y_pred_test = xgb_model.predict(X_test)
    # Make prediction on train data
    y_pred_train = xgb_model.predict(X_train)


    # Create Reduced dataset (basically X_reduced = X_train + y_train)
    reduced_df = X_train.copy()
    reduced_df["percent_houses_damaged"] = y_train.values
    reduced_df["predicted_value"] = y_pred_train

    # Just Predicted Damage dataset
    fliterd_df = reduced_df[reduced_df.predicted_value == 1]

    """      STEP 3: 2SG-Model part 2, Regression      """

    ### Third step is to train XGBoost regression model for this reduced train data (including damg>10.0%)
    bin_index2 = np.digitize(fliterd_df["percent_houses_damaged"], bins=bins_def[-1:])
    y_input_strat2 = bin_index2

    # Split X and y from dataframe features (JUST WHEN predicted_value == 1, i.e fliterd_df)
    X_r = fliterd_df[features]
    y_r = fliterd_df["percent_houses_damaged"]

    # XGBoost Reduced Overfitting
    xgbR = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )

    eval_set = [(X_r, y_r)]
    xgbR_model = xgbR.fit(X_r, y_r, eval_set=eval_set, verbose=False)
    high_damage_models.append(xgbR_model)

    # Make prediction on train and global test data
    y_pred_r = xgbR.predict(X_r)
    y_pred_test_total = xgbR.predict(X_test)

    # Calculate RMSE in total
    mse_train_idxR = mean_squared_error(y_r, y_pred_r)
    rmse_trainR = np.sqrt(mse_train_idxR)

    mse_idxR = mean_squared_error(y_test, y_pred_test_total)
    rmseR = np.sqrt(mse_idxR)

    """      STEP 4: 2SG-Model part 3, All together      """

    ## Last step is to add model combination (model M1 with model MR)
    # Check the result of classifier for TEST SET
    reduced_test_df = X_test.copy()

    # joined X_test with countinous target and binary predicted values with Classificator XGB (step 2)
    reduced_test_df["percent_houses_damaged"] = y_test.values
    reduced_test_df["predicted_value"] = y_pred_test

    # damaged prediction
    fliterd_test_df1 = reduced_test_df[reduced_test_df.predicted_value == 1]
    # not damaged prediction
    fliterd_test_df0 = reduced_test_df[reduced_test_df.predicted_value == 0]

    # keep only the features
    X1 = fliterd_test_df1[features] #just damage
    X0 = fliterd_test_df0[features] #not damage

    # For the output equal to 1 apply XGBReg (step 3) to evaluate the performance
    y1_pred = xgbR.predict(X1)
    y1 = fliterd_test_df1["percent_houses_damaged"]

    # For the output equal to 0 apply XGBReg (M1-Model -510 model- of step 1) to evaluate the performance
    y0_pred = xgb.predict(X0)
    y0 = fliterd_test_df0["percent_houses_damaged"]

    fliterd_test_df0["predicted_percent_damage"] = y0_pred
    fliterd_test_df1["predicted_percent_damage"] = y1_pred

    # Join two dataframes together
    join_test_dfs = pd.concat([fliterd_test_df0, fliterd_test_df1])

    """      STEP 5: 2SG-Model part 4, Calculate final stuff      """

    # Calculate RMSE in total
    mse_combined_model = mean_squared_error(
        join_test_dfs["percent_houses_damaged"],
        join_test_dfs["predicted_percent_damage"],
    )

    rmse_combined_model = np.sqrt(mse_combined_model)
    rmse_combined.append(rmse_combined_model)

    # Calculate RMSE per bin
    y_join = join_test_dfs["percent_houses_damaged"]
    y_pred_join = join_test_dfs["predicted_percent_damage"]

    y_test_typhoon_combined.append(y_join)
    y_pred_typhoon_combined.append(y_pred_join)

    # Per bin
    bin_index_test = np.digitize(y_join, bins=bins_def[:-1])
    RSME_combined_model = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_join[bin_index_test == bin_num]) != 0 and len(y_pred_join[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(
                y_join[bin_index_test == bin_num],
                y_pred_join[bin_index_test == bin_num],
            )
            rmse_test = np.sqrt(mse_test)
            RSME_combined_model.append(rmse_test)
        else:
           RSME_combined_model.append(np.nan)


    rmse_bin_combined.append(RSME_combined_model)
```

#### 2SG-XGB Results

```python
fig, ax = plt.subplots(10,4, figsize=(12,24))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon_combined[i], y_pred_typhoon_combined[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[16].set_ylabel('y pred [% of damage]', size=20)
ax[37].set_xlabel('y test [% of damage]', size=20)

#plt.suptitle('2SG-XGBoost Regression using LOOCV')
fig.delaxes(ax[39])
fig.delaxes(ax[38])
plt.tight_layout()
plt.show()
```

```python
#total RMSE
print('2SG-XGB_mean_RMSE_total: ', np.nanmean(rmse_combined))
```

```python
rmse_strat_combined = []
for i in range(num_bins):
    test_rmse_bin = np.nanmean(np.array(rmse_bin_combined)[:,i])
    rmse_strat_combined.append(test_rmse_bin)
#rmse_strat_combined
```

```python
plt.plot(range(num_bins), rmse_strat_combined, 'bs')
plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('2SG-XGBoost model')
plt.grid()
plt.show()
```

### Models comparison

```python
total_rmse_dum = np.round(np.nanmean(rmse_dummy),3)
total_rmse_comb = np.round(np.nanmean(rmse_combined),3)
rmse_strat_paper = [1.25, 6.07, 11.02, 20.39, 51.50]
total_rmse_paper = 2.92
plt.plot(range(num_bins), rmse_strat_dummy, 'go', alpha=0.9, label='Baseline model\nTotal Rmse: {}'.format(total_rmse_dum))
plt.plot(range(num_bins), rmse_strat_combined, 'k*', alpha=0.5, label='2SG-XGBoost model\nTotal Rmse: {}'.format(total_rmse_comb))
plt.plot(range(num_bins), rmse_strat_paper, 'o', alpha=0.5, label="Results from Mersedeh's codes (all features)\nTotal Rmse: {}".format(total_rmse_paper))


plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('RMSE per bin (Philippines dataset)')
plt.grid()
plt.legend()
plt.show()
```

This is almost identical to the values obtained in the Philippines dataset with all the features.


## Predict Fiji damage with Philippines trained model



### Simple model 1

- XGB model trained on all Philippines dataset

```python
"""      STEP 0: TRAIN TEST SPLIT      """

# Train on Philippines dataset
X_train = df[features]
y_train = df["percent_houses_damaged"]

# Test on Fiji
X_test = df_fji[features]
y_test = df_fji["percent_houses_damaged"]

# Stratify data
bin_index_test = np.digitize(y_test, bins=bins_def_fji[:-1])
bin_index_train = np.digitize(y_train, bins=bins_def[:-1])


"""      STEP 1: XGB-model (510 model or M-model)      """

# XGBoost Reduced Overfitting
xgb = XGBRegressor(
    base_score=0.5,
    booster="gbtree",
    colsample_bylevel=0.8,
    colsample_bynode=0.8,
    colsample_bytree=0.8,
    gamma=3,
    eta=0.01,
    importance_type="gain",
    learning_rate=0.1,
    max_delta_step=0,
    max_depth=4,
    min_child_weight=1,
    missing=1,
    n_estimators=100,
    early_stopping_rounds=10,
    n_jobs=1,
    nthread=None,
    objective="reg:squarederror",
    reg_alpha=0,
    reg_lambda=1,
    scale_pos_weight=1,
    seed=None,
    silent=None,
    subsample=0.8,
    verbosity=0,
    eval_metric=["rmse", "logloss"],
    random_state=0,
)

eval_set = [(X_train, y_train)]
xgb_model = xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)

"""      STEP 2: Prediction on Fiji      """

# Make prediction on train and test data
y_pred_phl = xgb.predict(X_train)
y_pred_fji = xgb.predict(X_test)

"""      STEP 3: Predictions per bin      """

# Per bin (Stratification)
rmse_test_bin_xgb_fji = []
avg_error_bin_xgb_fji = []
for bin_num in range(num_bins_fji+1)[1:]:
    if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred_fji[bin_index_test == bin_num]) != 0):
        # Estimation of RMSE for test data per each bin
        mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred_fji[bin_index_test == bin_num])
        rmse_test = np.sqrt(mse_test)
        rmse_test_bin_xgb_fji.append(rmse_test)
        # Avg error
        mean_difference = np.mean(y_test[bin_index_test == bin_num] - y_pred_fji[bin_index_test == bin_num])
        avg_error_bin_xgb_fji.append(mean_difference)
    else:
        rmse_test_bin_xgb_fji.append(np.nan)
        avg_error_bin_xgb_fji.append(np.nan)


```

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))
ax[0].plot(range(num_bins_fji), rmse_test_bin_xgb_fji, 'bs')
ax[0].set_xticks(range(num_bins_fji), str_bin_fji, rotation=45)
ax[0].set_xlabel('Damage [%]')
ax[0].set_ylabel('RMSE')
ax[0].grid()

ax[1].plot(range(num_bins_fji), avg_error_bin_xgb_fji, 'bs')
ax[1].set_xticks(range(num_bins_fji), str_bin_fji, rotation=45)
ax[1].set_xlabel('Damage [%]')
ax[1].set_ylabel('Avg error ')
ax[1].grid()

plt.suptitle('XGBoost Regression model trained on Philippines dataset')
plt.tight_layout()
plt.show()
```

### Simple model 2: combining training data

- We train on Philippines + Fiji data using LOOCV

```python
all_features = features + ['percent_houses_damaged'] + ['typhoon_name'] + ['country']
# New feature
df['country'] = 'phl'
df_fji['country'] = 'fji'

# All together
df_combined = pd.concat([df[all_features], df_fji[all_features]], axis=0)
all_typhoons = df_combined.typhoon_name.unique()
fji_typhoons = df_fji.typhoon_name.unique()
```

```python
rmse_total_fji = []
rmse_bin_fji = []
avg_error_bin_fji = []

y_test_typhoon_fji  = []
y_pred_typhoon_fji  = []

fji_weight = 3
for typhoon in fji_typhoons:

    """ PART 1: Train/Test """

    # LOOCV
    df_test = df_fji[df_fji["typhoon_name"] == typhoon] # Test set: Fiji
    df_train = df_combined[df_combined["typhoon_name"] != typhoon] # Train set: everything

    # Class weight
    weights = np.where(df_train['country'] == 'phl', 1, fji_weight) # Let's give more weight to Fiji

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def_fji[:-1])

    """ PART 2: XGB regressor """
    # create an XGBoost Regressor
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )


    # fit it on the training set
    eval_set = [(X_train, y_train)]
    xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False, sample_weight=weights) #xgb_model

    # make predictions on Fiji
    y_pred_fji = xgb.predict(X_test)

    # Save y_test y_pred
    y_test_typhoon_fji.append(y_test)
    y_pred_typhoon_fji.append(y_pred_fji)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred_fji)
    rmse_test = np.sqrt(mse_test)
    rmse_total_fji.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin = []
    avg_error_bin = []
    for bin_num in range(num_bins_fji+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred_fji[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred_fji[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin.append(rmse_test)
            # Avg error
            mean_difference = np.mean(y_test[bin_index_test == bin_num] - y_pred_fji[bin_index_test == bin_num])
            avg_error_bin.append(mean_difference)
        else:
            rmse_test_bin.append(np.nan)
            avg_error_bin.append(np.nan)

    rmse_bin_fji.append(rmse_test_bin)
    avg_error_bin_fji.append(avg_error_bin)
```

```python
rmse_strat_fji = []
avg_error_strat_fji = []
for i in range(num_bins_fji):
    #RMSE
    test_rmse_bin = np.nanmean(np.array(rmse_bin_fji)[:,i])
    rmse_strat_fji.append(test_rmse_bin)
    #AVG error
    test_avg_bin = np.nanmean(np.array(avg_error_bin_fji)[:,i])
    avg_error_strat_fji.append(test_avg_bin)
```

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))
ax[0].plot(range(num_bins_fji), rmse_strat_fji, 'bs')
ax[0].set_xticks(range(num_bins_fji), str_bin_fji, rotation=45)
ax[0].set_xlabel('Damage [%]')
ax[0].set_ylabel('RMSE')
ax[0].grid()

ax[1].plot(range(num_bins_fji), avg_error_strat_fji, 'bs')
ax[1].set_xticks(range(num_bins_fji), str_bin_fji, rotation=45)
ax[1].set_xlabel('Damage [%]')
ax[1].set_ylabel('Avg error ')
ax[1].grid()

plt.suptitle('XGBoost Regression model trained on Philippines+Fiji \ndataset using LOOCV for Fiji typhoons')
plt.tight_layout()
plt.show()
```

#### Comparison Fiji and Fiji+Philippines training for predicting damage

```python
fig, ax = plt.subplots(1,1, figsize=(6,6))

ax.plot(range(num_bins_fji), rmse_strat_xgb, 'bs', label='Model trained on Fiji subset')
ax.plot(range(num_bins_fji), rmse_strat_fji, 'rs', label='Model trained with Fiji + Philippines datasets \nwith 3:1 weight sample ratio')

ax.set_xticks(range(num_bins_fji), str_bin_fji, rotation=45)
ax.legend()
ax.set_xlabel('Damage [%]')
ax.set_ylabel('RMSE')
ax.set_title('XGBoost Regression model trained on different datasets \nusing LOOCV for Fiji typhoons')
ax.grid()

```

### Dumb approach

The approach is going to be the following:

- Use every high damage model used for every typhoon in the LOOCV train/test split in the Philippines dataset
- Also use the classic XGB model just to see and compare
- Predict Fiji data which each model for every typhoon
- Take the avg damage predicted data
- Compute avg damage real data - avg damage predicted data

```python
fji_typhoons = df_fji.typhoon_name.unique()

y_real = [] # Actual damage for every typhoon
y_pred_hd = [] # Predictions for every grid cell for every typhoon using the high damage model
y_pred_m1 = [] # Predictions for every grid cell for every typhoon using the M1 (XGB) model
y_pred_combined = [] # Predictions for every grid cell for every typhoon using the combined model
y_pred_class = []
avg_error_hd = []
avg_error_m1 = []
avg_error_combined = []

for typhoon in fji_typhoons:
    df_fji_typhoon = df_fji[df_fji.typhoon_name == typhoon]

    X_fji = df_fji_typhoon[features] # Fiji dataset to make predictions on
    y_fji = df_fji_typhoon['percent_houses_damaged'] # Actual damage

    # High damage model
    y_pred_model = []
    for model in high_damage_models:
        # Make predictions on the new data using the current model
        y_pred = model.predict(X_fji)
        y_pred_model.append(y_pred)

    y_pred_hd.append(y_pred_model)

    # Avg error
    mean_dmg_predicted = np.mean(y_pred_model)
    mean_dmg_real = np.mean(y_fji, axis=0)
    avg_error_hd.append(mean_dmg_real - mean_dmg_predicted)

    # M1 model (XGB)
    y_pred_model = []
    for model in M1_models:
        # Make predictions on the new data using the current model
        y_pred = model.predict(X_fji)
        y_pred_model.append(y_pred)

    y_pred_m1.append(y_pred_model)

    # Avg error
    mean_dmg_predicted = np.mean(y_pred_model)
    mean_dmg_real = np.mean(y_fji, axis=0)
    avg_error_m1.append(mean_dmg_real - mean_dmg_predicted)

    # Combined model
    y_pred_binary = []
    for model in classification_models:
        # Make predictions on the new data using the current model
        y_pred = model.predict(X_fji)
        y_pred_binary.append(y_pred)

    # Binary Classification approach


    avg_error_hd_combined = []
    avg_error_ld_combined = []
    for prediction in y_pred_binary:
        X_fji2 = X_fji.copy()
        y_fji2 = y_fji.copy()
        X_fji2['real_dmg'] = y_fji2
        X_fji2['pred_binary'] = prediction
        # Binary High damage and Low damage predictions
        X_hd = X_fji2[X_fji2['pred_binary'] == 1]
        X_ld = X_fji2[X_fji2['pred_binary'] == 0]
        real_dmg_hd = X_hd['real_dmg']
        real_dmg_ld = X_ld['real_dmg']
        # Mask the info
        X_hd = X_hd.drop(['pred_binary', 'real_dmg'], axis=1)
        X_ld = X_ld.drop(['pred_binary', 'real_dmg'], axis=1)

        reg_prediction_hd = []
        for model in high_damage_models:
            reg_prediction_hd.append(model.predict(X_hd))

        mean_hd_dmg = np.nanmean(reg_prediction_hd)
        mean_real_dmg = np.mean(real_dmg_hd)
        avg_error_hd_combined.append(mean_real_dmg - mean_hd_dmg)

        reg_prediction_ld = []
        for model in M1_models:
            reg_prediction_ld.append(model.predict(X_ld))

        mean_ld_dmg = np.nanmean(reg_prediction_ld)
        mean_real_dmg = np.mean(real_dmg_ld)
        avg_error_ld_combined.append(mean_real_dmg - mean_ld_dmg)

    avg_error_combined.append(np.nanmean(avg_error_hd_combined + avg_error_ld_combined))
```

What I did:

- Iterate thrugh every typhoon for Fiji
- In every typhoon I use all the models for Fiji (all the XGB models and all the highdamage models)
- So I have a bunch of predictions for every typhoon
- I took the mean of each prediction


```python
plt.plot(range(0,len(fji_typhoons)), avg_error_hd, 'o', label='High damage model')
plt.plot(range(0,len(fji_typhoons)), avg_error_m1, 'ro', label='XGB model')
plt.plot(range(0,len(fji_typhoons)), avg_error_combined, 'go', label='Combined model')
plt.xticks(range(0,len(fji_typhoons)), fji_typhoons, rotation=45)
plt.xlabel('')
plt.ylabel('Actual dmg - Predicted dmg [%]', size=12)
plt.legend()
plt.grid()
plt.show()
```
