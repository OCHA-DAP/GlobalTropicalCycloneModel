---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: env1
    language: python
    name: env1
---

```python
import statistics

from sklearn import preprocessing
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from xgboost.sklearn import XGBRegressor
from sklearn.dummy import DummyRegressor
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import statsmodels.api as sm

from utils import get_training_dataset_complete, RS_BASE
```

## Data cleaning and stratification

```python
df_complete = get_training_dataset_complete()
df = df_complete.copy()
df = df.rename({'perc_dmg_grid':'percent_houses_damaged', 'total_buildings':'total_houses'}, axis=1)
```

```python
# Set any values of damage houses >100% to 100% .. ok
for r in range(len(df)):
    if df.loc[r, "percent_houses_damaged"] > 100:
        df.at[r, "percent_houses_damaged"] = float(100)
```

```python
#drop windspeed = 0
# df = (df[(df[["wind_speed"]] != 0).any(axis=1)]).reset_index(drop=True)
# df = df.drop(columns=["grid_point_id", "typhoon_year_y", "typhoon_year"])
```

```python
#what about rainfall data? Lets drop all 0 values.
# df = (df[(df[["rainfall_max_24h"]] != 0).any(axis=1)]).reset_index(drop=True)
# df = (df[(df[["rainfall_max_6h"]] != 0).any(axis=1)]).reset_index(drop=True)
# df.typhoon_name.unique()
```

### Stratification

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))

ax[0].hist(df.percent_houses_damaged, edgecolor='black')
ax[0].set_xlabel('% Houses Damaged',size=15)
ax[0].set_ylabel('Frequency',size=15)

hist = np.histogram(df.percent_houses_damaged, bins=10 ** np.linspace(0, np.log10(10**1.5), len(df)), density=True)
x = hist[1][:-1]
y = hist[0]

ax[1].plot(x,y, 'ro', alpha=0.4, label='housing damage')
ax[1].set_xscale('log')
ax[1].set_yscale('log')
ax[1].set_xlabel('% Houses Damaged', size=15)
ax[1].set_ylabel('Frequency', size=15) #PDF (% Houses Damaged)
ax[1].grid(c='black', alpha=0.3)
ax[1].legend()

plt.tight_layout()
plt.show()
```

```python
#Lets look for the perfect binning
dmg = np.array(df.percent_houses_damaged.to_list())
offset = 1e-8
dmg_off = dmg + offset
x = list(np.linspace(0,1,101))
info = []
for i in x:
    info.append(np.quantile(dmg_off, i))

plt.plot(x,info,'o')
plt.xlabel('Quantile')
plt.ylabel('Damage [%]')
plt.yscale('log')
plt.title('Damage Offset = {}'.format(offset))
plt.grid()
plt.show()
```

```python
# Stratification
zero_dmg = np.round((np.count_nonzero(dmg == 0) / len(dmg)) , 2 )

# Define ranges for each group
x0 = list(np.linspace(0, zero_dmg, 1))   # zero damage
x1 = list(np.linspace(zero_dmg, 0.93, 2))  # almost no damage
x2 = list(np.linspace(0.935, 1, 5))  # all the damage
x3=x0+x1+x2

bins = []
for i in x3:
    bins.append(np.quantile(dmg, i))

# Histogram after stratification
samples_per_bin, bins_def = np.histogram(dmg, bins=bins)
print(samples_per_bin)

# Define number of bins
num_bins = len(samples_per_bin)

y_input_strat = np.digitize(dmg, bins=bins_def[:-1]) #remove the last one because there's no value with 100% dmg
```

```python
# For future plots
str_bin = []
for i in range(len(bins_def[:-1])):
    a = str(np.round(bins_def[i+1],3))
    b = str(np.round(bins_def[i],3))
    str_bin.append('{} - {}'.format(b,a))
str_bin
```

## Models

```python
df
```

```python
# List of typhoons
typhoons = df.typhoon_name.unique()

# Specify features
features = [
    "wind_speed",
    "track_distance",
    "total_houses",
    "rainfall_max_6h",
    "rainfall_max_24h",
    "coast_length",
    "with_coast",
    "mean_altitude",
    "mean_slope",
    "IWI"
]
```

### Baseline dummy model

```python
rmse_dummy = []
rmse_bin_dummy = []
avg_error_bin_dummy = []

y_test_typhoon = []
y_pred_typhoon = []

for typhoon in typhoons:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def[:-1])

    """ PART 2: Dummy regressor """
    # create a dummy regressor
    dummy_reg = DummyRegressor(strategy="mean")

    # fit it on the training set
    dummy_reg.fit(X_train, y_train)

    # make predictions on the test set
    y_pred = dummy_reg.predict(X_test)
    # make predictions on the train set
    y_pred_train = dummy_reg.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon.append(y_test)
    y_pred_typhoon.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_dummy.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin = []
    avg_error_test_bin_dummy = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin.append(rmse_test)
            # Avg error
            mean_difference = np.mean(y_test[bin_index_test == bin_num] - y_pred[bin_index_test == bin_num])
            avg_error_test_bin_dummy.append(mean_difference)

        else:
            rmse_test_bin.append(np.nan)

    rmse_bin_dummy.append(rmse_test_bin)
    avg_error_bin_dummy.append(avg_error_test_bin_dummy)
```

#### Dummy model results

```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon[i], y_pred_typhoon[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)
plt.suptitle('Dummy model using LOOCV \n(it always predict the mean value of the damage)')
plt.tight_layout()
plt.show()
```

```python
#total RMSE
print('dummy_mean_RMSE_total: ', np.nanmean(rmse_dummy))
```

```python
rmse_strat_dummy = []
avg_error_strat_dummy = []
for i in range(num_bins):
    #RMSE
    dummy_test_rmse_bin = np.nanmean(np.array(rmse_bin_dummy)[:,i])
    rmse_strat_dummy.append(dummy_test_rmse_bin)
    #AVG error
    test_avg_bin = np.nanmean(np.array(avg_error_bin_linreg)[:,i])
    avg_error_strat_dummy.append(test_avg_bin)

```

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))
ax[0].plot(range(num_bins), rmse_strat_dummy, 'bs')
ax[0].set_xticks(range(num_bins), str_bin, rotation=45)
ax[0].set_xlabel('Damage [%]')
ax[0].set_ylabel('RMSE')
ax[0].grid()

ax[1].plot(range(num_bins), avg_error_strat_dummy, 'bs')
ax[1].set_xticks(range(num_bins), str_bin, rotation=45)
ax[1].set_xlabel('Damage [%]')
ax[1].set_ylabel('Avg error ')
ax[1].grid()

plt.suptitle('Dummy model')
plt.tight_layout()
plt.show()
```

### Linear Regressor

```python
from sklearn.linear_model import LinearRegression
rmse_linreg = []
rmse_bin_linreg = []
avg_error_bin_linreg = []

y_test_typhoon_linreg = []
y_pred_typhoon_linreg = []

for typhoon in typhoons:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def[:-1])

    """ PART 2: Linear regressor """
    # create a dummy regressor
    reg = LinearRegression()

    # fit it on the training set
    reg.fit(X_train, y_train)

    # make predictions on the test set
    y_pred = reg.predict(X_test)
    # make predictions on the train set
    y_pred_train = reg.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon_linreg.append(y_test)
    y_pred_typhoon_linreg.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_linreg.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin_linreg = []
    avg_error_test_bin_linear = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin_linreg.append(rmse_test)
            # Avg error
            mean_difference = np.mean(y_test[bin_index_test == bin_num] - y_pred[bin_index_test == bin_num])
            avg_error_test_bin_linear.append(mean_difference)
        else:
            rmse_test_bin_linreg.append(np.nan)
            avg_error_test_bin_linear.append(np.nan)

    rmse_bin_linreg.append(rmse_test_bin_linreg)
    avg_error_bin_linreg.append(avg_error_test_bin_linear)
```

#### Linear Regressor results

```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon_linreg[i], y_pred_typhoon_linreg[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)

plt.suptitle('Linear Regression using LOOCV')
plt.tight_layout()
plt.show()
```

```python
#total RMSE
print('LinReg_mean_RMSE_total: ', np.nanmean(rmse_linreg))
```

```python
rmse_strat_linreg = []
avg_error_strat_linreg = []
for i in range(num_bins):
    #RMSE
    test_rmse_bin = np.nanmean(np.array(rmse_bin_linreg)[:,i])
    rmse_strat_linreg.append(test_rmse_bin)
    #AVG error
    test_avg_bin = np.nanmean(np.array(avg_error_bin_linreg)[:,i])
    avg_error_strat_linreg.append(test_avg_bin)

```

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))
ax[0].plot(range(num_bins), rmse_strat_linreg, 'bs')
ax[0].set_xticks(range(num_bins), str_bin, rotation=45)
ax[0].set_xlabel('Damage [%]')
ax[0].set_ylabel('RMSE')
ax[0].grid()

ax[1].plot(range(num_bins), avg_error_strat_linreg, 'bs')
ax[1].set_xticks(range(num_bins), str_bin, rotation=45)
ax[1].set_xlabel('Damage [%]')
ax[1].set_ylabel('Avg error ')
ax[1].grid()

plt.suptitle('Linear Regressor model')
plt.tight_layout()
plt.show()

```

### XGBoost

```python
from xgboost.sklearn import XGBRegressor
rmse_xgb = []
rmse_bin_xgb = []
avg_error_bin_xgb = []

y_test_typhoon_xgb  = []
y_pred_typhoon_xgb  = []

for typhoon in typhoons:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def[:-1])

    """ PART 2: Linear regressor """
    # create an XGBoost Regressor
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )


    # fit it on the training set
    eval_set = [(X_train, y_train)]
    xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False) #xgb_model

    # make predictions on the test set
    y_pred = xgb.predict(X_test)
    # make predictions on the train set
    y_pred_train = xgb.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon_xgb.append(y_test)
    y_pred_typhoon_xgb.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_xgb.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin_xgb = []
    avg_error_test_bin_xgb = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin_xgb.append(rmse_test)
            # Avg error
            mean_difference = np.mean(y_test[bin_index_test == bin_num] - y_pred[bin_index_test == bin_num])
            avg_error_test_bin_xgb.append(mean_difference)
        else:
            rmse_test_bin_xgb.append(np.nan)
            avg_error_test_bin_xgb.append(np.nan)
    rmse_bin_xgb.append(rmse_test_bin_xgb)
    avg_error_bin_xgb.append(avg_error_test_bin_xgb)
```

#### XGBoost regressor results

```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon_xgb[i], y_pred_typhoon_xgb[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)

plt.suptitle('XGBoost Regression using LOOCV')
plt.tight_layout()
plt.show()
```

```python
#total RMSE
print('XGB_mean_RMSE_total: ', np.nanmean(rmse_xgb))
```

```python
rmse_strat_xgb = []
avg_error_strat_xgb = []
for i in range(num_bins):
    #RMSE
    test_rmse_bin = np.nanmean(np.array(rmse_bin_xgb)[:,i])
    rmse_strat_xgb.append(test_rmse_bin)
    #AVG error
    test_avg_bin = np.nanmean(np.array(avg_error_bin_xgb)[:,i])
    avg_error_strat_xgb.append(test_avg_bin)

```

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))
ax[0].plot(range(num_bins), rmse_strat_xgb, 'bs')
ax[0].set_xticks(range(num_bins), str_bin, rotation=45)
ax[0].set_xlabel('Damage [%]')
ax[0].set_ylabel('RMSE')
ax[0].grid()

ax[1].plot(range(num_bins), avg_error_strat_xgb, 'bs')
ax[1].set_xticks(range(num_bins), str_bin, rotation=45)
ax[1].set_xlabel('Damage [%]')
ax[1].set_ylabel('Avg error ')
ax[1].grid()

plt.suptitle('XGBoost Regression model')
plt.tight_layout()
plt.show()

```

### XGB-Classifier

```python
thres = 3 # Damage threshold
df[df.percent_houses_damaged >= thres]
```

```python
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from matplotlib import cm
from mlxtend.plotting import plot_confusion_matrix

cms = []
accuracy =[]

for typhoon in typhoons:

    """      STEP 0: TRAIN TEST SPLIT LOOCV     """

    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    """      STEP 1: XGB CLASSIFIER     """
    # Define a threshold to separate target into damaged and not_damaged
    y_test_bool = y_test >= thres
    y_train_bool = y_train >= thres
    y_test_bin = (y_test_bool) * 1 #nice way to concert boolean to binary
    y_train_bin = (y_train_bool) * 1


    # Use XGBClassifier as a Machine Learning model to fit the data
    xgb_model = XGBClassifier(eval_metric=["error", "logloss"])
    eval_set = [(X_test, y_test_bin)]
    xgb_model.fit(X_train,y_train_bin,eval_set=eval_set,verbose=False)

    # Make prediction on test data
    y_pred_test = xgb_model.predict(X_test)
    # Make prediction on train data
    y_pred_train = xgb_model.predict(X_train)

    # Accuracy
    acc = accuracy_score(y_test_bin, y_pred_test)
    accuracy.append(acc)

    # Confussion matrix
    cm = confusion_matrix(y_test_bin, y_pred_test)
    cms.append(cm)
```

```python
# Total cm
overall_confusion_matrix = np.zeros((2, 2))
for confusion_matrix in cms:
    overall_confusion_matrix += confusion_matrix

# Plot Confusion Matrix
fig, ax = plot_confusion_matrix(
    conf_mat=overall_confusion_matrix,
    show_absolute=True,
    show_normed=False,
    colorbar=False,
    cmap=plt.cm.Greens,
)
ax.set_xlabel('')
ax.set_ylabel('')
ax.xaxis.set(ticks=(0, 1), ticklabels=("Predicted 0s", "Predicted 1s"))
ax.yaxis.set(ticks=(0, 1), ticklabels=("Actual 0s", "Actual 1s"))
ax.set_title("Confusion Matrix for XGBoost Model\nthreshold = {} %".format(thres))
plt.show()
```

```python
# Accuracy
print('XGB-Classifier Accuracy: {}'.format(np.mean(accuracy)))
```

### 2SG-XGB

```python
thres = 3 # Damage threshold
df[df.percent_houses_damaged >= thres]
```

```python
from xgboost import XGBClassifier
rmse_combined = []
rmse_bin_combined = []
avg_error_bin_combined = []

y_test_typhoon_combined = []
y_pred_typhoon_combined = []

i=0
for typhoon in typhoons:

    """      STEP 0: TRAIN TEST SPLIT      """

    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    print('{}/{} '.format(i+1, len(typhoons)),typhoon)
    i+=1

    """      STEP 1: M-model (510 model)      """

    # XGBoost Reduced Overfitting
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )

    eval_set = [(X_train, y_train)]
    xgb_model = xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)

    # Make prediction on train and test data
    y_pred_train = xgb.predict(X_train)
    y_pred = xgb.predict(X_test)

    # Calculate RMSE in total
    mse_train_idx = mean_squared_error(y_train, y_pred_train)
    rmse_train = np.sqrt(mse_train_idx)

    mse_idx = mean_squared_error(y_test, y_pred)
    rmseM1 = np.sqrt(mse_idx)

    """      STEP 2: 2SG-Model part 1, Classifier      """

    # Define a threshold to separate target into damaged and not_damaged
    y_test_bool = y_test >= thres
    y_train_bool = y_train >= thres
    y_test_bin = (y_test_bool) * 1 #nice way to concert boolean to binary
    y_train_bin = (y_train_bool) * 1


    # Use XGBClassifier as a Machine Learning model to fit the data
    xgb_model = XGBClassifier(eval_metric=["error", "logloss"])
    eval_set = [(X_test, y_test_bin)]
    xgb_model.fit(X_train,y_train_bin,eval_set=eval_set,verbose=False)

    # Make prediction on test data
    y_pred_test = xgb_model.predict(X_test)
    # Make prediction on train data
    y_pred_train = xgb_model.predict(X_train)


    # Create Reduced dataset (basically X_reduced = X_train + y_train)
    reduced_df = X_train.copy()
    reduced_df["percent_houses_damaged"] = y_train.values
    reduced_df["predicted_value"] = y_pred_train

    # Just Predicted Damage dataset
    fliterd_df = reduced_df[reduced_df.predicted_value == 1]

    """      STEP 3: 2SG-Model part 2, Regression      """

    ### Third step is to train XGBoost regression model for this reduced train data (including damg>10.0%)
    bin_index2 = np.digitize(fliterd_df["percent_houses_damaged"], bins=bins_def[-1:])
    y_input_strat2 = bin_index2

    # Split X and y from dataframe features (JUST WHEN predicted_value == 1, i.e fliterd_df)
    X_r = fliterd_df[features]
    y_r = fliterd_df["percent_houses_damaged"]

    # XGBoost Reduced Overfitting
    xgbR = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )

    eval_set = [(X_r, y_r)]
    xgbR_model = xgbR.fit(X_r, y_r, eval_set=eval_set, verbose=False)

    # Make prediction on train and global test data
    y_pred_r = xgbR.predict(X_r)
    y_pred_test_total = xgbR.predict(X_test)

    # Calculate RMSE in total
    mse_train_idxR = mean_squared_error(y_r, y_pred_r)
    rmse_trainR = np.sqrt(mse_train_idxR)

    mse_idxR = mean_squared_error(y_test, y_pred_test_total)
    rmseR = np.sqrt(mse_idxR)

    """      STEP 4: 2SG-Model part 3, All together      """

    ## Last step is to add model combination (model M1 with model MR)
    # Check the result of classifier for TEST SET
    reduced_test_df = X_test.copy()

    # joined X_test with countinous target and binary predicted values with Classificator XGB (step 2)
    reduced_test_df["percent_houses_damaged"] = y_test.values
    reduced_test_df["predicted_value"] = y_pred_test

    # damaged prediction
    fliterd_test_df1 = reduced_test_df[reduced_test_df.predicted_value == 1]
    # not damaged prediction
    fliterd_test_df0 = reduced_test_df[reduced_test_df.predicted_value == 0]

    # keep only the features
    X1 = fliterd_test_df1[features] #just damage
    X0 = fliterd_test_df0[features] #not damage

    # For the output equal to 1 apply XGBReg (step 3) to evaluate the performance
    y1_pred = xgbR.predict(X1)
    y1 = fliterd_test_df1["percent_houses_damaged"]

    # For the output equal to 0 apply XGBReg (M1-Model -510 model- of step 1) to evaluate the performance
    y0_pred = xgb.predict(X0)
    y0 = fliterd_test_df0["percent_houses_damaged"]

    fliterd_test_df0["predicted_percent_damage"] = y0_pred
    fliterd_test_df1["predicted_percent_damage"] = y1_pred

    # Join two dataframes together
    join_test_dfs = pd.concat([fliterd_test_df0, fliterd_test_df1])

    """      STEP 5: 2SG-Model part 4, Calculate final stuff      """

    # Calculate RMSE in total
    mse_combined_model = mean_squared_error(
        join_test_dfs["percent_houses_damaged"],
        join_test_dfs["predicted_percent_damage"],
    )

    rmse_combined_model = np.sqrt(mse_combined_model)
    rmse_combined.append(rmse_combined_model)

    # Calculate RMSE per bin
    y_join = join_test_dfs["percent_houses_damaged"]
    y_pred_join = join_test_dfs["predicted_percent_damage"]

    y_test_typhoon_combined.append(y_join)
    y_pred_typhoon_combined.append(y_pred_join)

    # Per bin
    bin_index_test = np.digitize(y_join, bins=bins_def[:-1])
    RSME_combined_model = []
    avg_error_bin = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_join[bin_index_test == bin_num]) != 0 and len(y_pred_join[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(
                y_join[bin_index_test == bin_num],
                y_pred_join[bin_index_test == bin_num],
            )
            rmse_test = np.sqrt(mse_test)
            RSME_combined_model.append(rmse_test)
            # Avg error
            mean_difference = np.mean(y_join[bin_index_test == bin_num] - y_pred_join[bin_index_test == bin_num])
            avg_error_bin.append(mean_difference)
        else:
            RSME_combined_model.append(np.nan)
            avg_error_bin.append(np.nan)

    avg_error_bin_combined.append(avg_error_bin)
    rmse_bin_combined.append(RSME_combined_model)
```

#### 2SG-XGB Results

```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon_combined[i], y_pred_typhoon_combined[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)

plt.suptitle('2SG-XGBoost Regression using LOOCV')
plt.tight_layout()
plt.show()
```

```python
#total RMSE
print('2SG-XGB_mean_RMSE_total: ', np.nanmean(rmse_combined))
```

```python
rmse_strat_combined = []
avg_error_strat_combined = []
for i in range(num_bins):
    #RMSE
    test_rmse_bin = np.nanmean(np.array(rmse_bin_combined)[:,i])
    rmse_strat_combined.append(test_rmse_bin)
    #AVG error
    test_avg_bin = np.nanmean(np.array(avg_error_bin_combined)[:,i])
    avg_error_strat_combined.append(test_avg_bin)

```

```python
fig, ax = plt.subplots(1,2, figsize=(10,6))
ax[0].plot(range(num_bins), rmse_strat_combined, 'bs')
ax[0].set_xticks(range(num_bins), str_bin, rotation=45)
ax[0].set_xlabel('Damage [%]')
ax[0].set_ylabel('RMSE')
ax[0].grid()

ax[1].plot(range(num_bins), avg_error_strat_combined, 'bs')
ax[1].set_xticks(range(num_bins), str_bin, rotation=45)
ax[1].set_xlabel('Damage [%]')
ax[1].set_ylabel('Avg error ')
ax[1].grid()

plt.suptitle('2SG-XGBoost model')
plt.tight_layout()
plt.show()
```

### Models comparison

```python
total_rmse_xgb = np.round(np.nanmean(rmse_xgb),3)
total_rmse_lin = np.round(np.nanmean(rmse_linreg),3)
total_rmse_dum = np.round(np.nanmean(rmse_dummy),3)
total_rmse_comb = np.round(np.nanmean(rmse_combined),3)

fig, ax = plt.subplots(1,2, figsize=(12,6))

ax[0].plot(range(num_bins), rmse_strat_xgb, 'bo', alpha=0.9, label='XGBoost Regression model\nTotal Rmse: {}'.format(total_rmse_xgb))
ax[0].plot(range(num_bins), rmse_strat_linreg, 'ro', alpha=0.9, label='Linear regression model\nTotal Rmse: {}'.format(total_rmse_lin))
ax[0].plot(range(num_bins), rmse_strat_dummy, 'go', alpha=0.9, label='Baseline model\nTotal Rmse: {}'.format(total_rmse_dum))
ax[0].plot(range(num_bins), rmse_strat_combined, 'k*', alpha=0.5, label='2SG-XGBoost model\nTotal Rmse: {}'.format(total_rmse_comb))
ax[0].set_xticks(range(num_bins), str_bin, rotation=45)
ax[0].set_xlabel('Damage [%]')
ax[0].set_ylabel('RMSE')
ax[0].set_title('RMSE per bin')
ax[0].grid()
ax[0].legend()



ax[1].plot(range(num_bins), avg_error_strat_xgb, 'bo', alpha=0.9, label='XGBoost Regression model')
ax[1].plot(range(num_bins), avg_error_strat_linreg, 'ro', alpha=0.9, label='Linear regression model')
ax[1].plot(range(num_bins), avg_error_strat_dummy, 'go', alpha=0.9, label='Baseline model')
ax[1].plot(range(num_bins), avg_error_strat_combined, 'k*', alpha=0.5, label='2SG-XGBoost model')
ax[1].set_xticks(range(num_bins), str_bin, rotation=45)
ax[1].set_xlabel('Damage [%]')
ax[1].set_ylabel('Avg error')
ax[1].set_title('Avg error per bin')
ax[1].grid()
ax[1].legend()


plt.show()
```
