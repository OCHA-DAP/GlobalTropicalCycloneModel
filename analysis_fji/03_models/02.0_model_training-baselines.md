```python
import statistics

from sklearn import preprocessing
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from xgboost.sklearn import XGBRegressor
from sklearn.dummy import DummyRegressor
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import statsmodels.api as sm

from utils import get_training_dataset_complete, RS_BASE
```

## Data cleaning and stratification


```python
df_complete = get_training_dataset_complete()
df = df_complete.copy()
df = df.rename({'perc_dmg_grid':'percent_houses_damaged', 'total_buildings':'total_houses'}, axis=1)
```


```python
df.columns
```




    Index(['index', 'typhoon_name', 'grid_point_id', 'typhoon_year_x',
           'wind_speed', 'track_distance', 'total_buildings_x',
           'total_buildings_damaged', 'percent_houses_damaged', 'typhoon_year_y',
           'rainfall_max_6h', 'rainfall_max_24h', 'Centroid', 'IWI',
           'total_houses', 'id', 'with_coast', 'coast_length', 'mean_altitude',
           'mean_slope'],
          dtype='object')




```python
# Set any values of damage houses >100% to 100% .. ok
for r in range(len(df)):
    if df.loc[r, "percent_houses_damaged"] > 100:
        df.at[r, "percent_houses_damaged"] = float(100)
```


```python
#drop windspeed = 0
# df = (df[(df[["wind_speed"]] != 0).any(axis=1)]).reset_index(drop=True)
# df = df.drop(columns=["grid_point_id", "typhoon_year_y", "typhoon_year"])
```


```python
#what about rainfall data? Lets drop all 0 values.
# df = (df[(df[["rainfall_max_24h"]] != 0).any(axis=1)]).reset_index(drop=True)
# df = (df[(df[["rainfall_max_6h"]] != 0).any(axis=1)]).reset_index(drop=True)
# df.typhoon_name.unique()
```

### Stratification


```python
fig, ax = plt.subplots(1,2, figsize=(10,6))

ax[0].hist(df.percent_houses_damaged, edgecolor='black')
ax[0].set_xlabel('% Houses Damaged',size=15)
ax[0].set_ylabel('Frequency',size=15)

hist = np.histogram(df.percent_houses_damaged, bins=10 ** np.linspace(0, np.log10(10**1.5), len(df)), density=True)
x = hist[1][:-1]
y = hist[0]

ax[1].plot(x,y, 'ro', alpha=0.4, label='housing damage')
ax[1].set_xscale('log')
ax[1].set_yscale('log')
ax[1].set_xlabel('% Houses Damaged', size=15)
ax[1].set_ylabel('Frequency', size=15) #PDF (% Houses Damaged)
ax[1].grid(c='black', alpha=0.3)
ax[1].legend()

plt.tight_layout()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_8_0.png)




```python
#Lets look for the perfect binning
dmg = np.array(df.percent_houses_damaged.to_list())
offset = 1e-8
dmg_off = dmg + offset
x = list(np.linspace(0,1,101))
info = []
for i in x:
    info.append(np.quantile(dmg_off, i))

plt.plot(x,info, 'o')
plt.xlabel('Quantile')
plt.ylabel('Damage [%]')
plt.yscale('log')
plt.title('Damage Offset = {}'.format(offset))
plt.grid()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_9_0.png)




```python
# Stratification
zero_dmg = np.round((np.count_nonzero(dmg == 0) / len(dmg)) , 2 )

# Define ranges for each group
x0 = list(np.linspace(0, zero_dmg, 1))   # zero damage
x1 = list(np.linspace(zero_dmg, 0.93, 2))  # almost no damage
x2 = list(np.linspace(0.935, 1, 5))  # all the damage
x3=x0+x1+x2

bins = []
for i in x3:
    bins.append(np.quantile(dmg, i))

# Histogram after stratification
samples_per_bin, bins_def = np.histogram(dmg, bins=bins)
print(samples_per_bin)

# Define number of bins
num_bins = len(samples_per_bin)

y_input_strat = np.digitize(dmg, bins=bins_def[:-1]) #remove the last one because there's no value with 100% dmg
```

    [1780 1668   19   60   60   60   61]



```python
# For future plots
str_bin = []
for i in range(len(bins_def[:-1])):
    a = str(np.round(bins_def[i+1],3))
    b = str(np.round(bins_def[i],3))
    str_bin.append('{} - {}'.format(b,a))
print(str_bin)
```

    ['0.0 - 0.0', '0.0 - 0.144', '0.144 - 0.158', '0.158 - 0.22', '0.22 - 0.387', '0.387 - 0.859', '0.859 - 9.805']


## Models


```python
# List of typhoons
typhoons = df.typhoon_name.unique()

# Specify features
features = [
    "wind_speed",
    "track_distance",
    "total_houses",
    "rainfall_max_6h",
    "rainfall_max_24h",
    #"coast_length",
    #"with_coast",
    #"mean_altitude",
    #"mean_slope",
    #"IWI"
]
```


```python
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>typhoon_name</th>
      <th>grid_point_id</th>
      <th>typhoon_year_x</th>
      <th>wind_speed</th>
      <th>track_distance</th>
      <th>total_buildings_x</th>
      <th>total_buildings_damaged</th>
      <th>percent_houses_damaged</th>
      <th>typhoon_year_y</th>
      <th>rainfall_max_6h</th>
      <th>rainfall_max_24h</th>
      <th>Centroid</th>
      <th>IWI</th>
      <th>total_houses</th>
      <th>id</th>
      <th>with_coast</th>
      <th>coast_length</th>
      <th>mean_altitude</th>
      <th>mean_slope</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>TOMAS</td>
      <td>175</td>
      <td>2010</td>
      <td>11.489542</td>
      <td>297.755905</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>2010</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>176.85E_-17.15N</td>
      <td>86.0</td>
      <td>0</td>
      <td>175</td>
      <td>1</td>
      <td>224.976542</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>EVAN</td>
      <td>175</td>
      <td>2012</td>
      <td>39.054266</td>
      <td>60.865460</td>
      <td>0.0</td>
      <td>437.666667</td>
      <td>0.0</td>
      <td>2012</td>
      <td>0.141667</td>
      <td>0.070833</td>
      <td>176.85E_-17.15N</td>
      <td>86.0</td>
      <td>0</td>
      <td>175</td>
      <td>1</td>
      <td>224.976542</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>WINSTON</td>
      <td>175</td>
      <td>2016</td>
      <td>51.661172</td>
      <td>40.384660</td>
      <td>0.0</td>
      <td>7735.000000</td>
      <td>0.0</td>
      <td>2016</td>
      <td>0.508333</td>
      <td>0.189583</td>
      <td>176.85E_-17.15N</td>
      <td>86.0</td>
      <td>0</td>
      <td>175</td>
      <td>1</td>
      <td>224.976542</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>GITA</td>
      <td>175</td>
      <td>2018</td>
      <td>0.000000</td>
      <td>444.116254</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>2018</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>176.85E_-17.15N</td>
      <td>86.0</td>
      <td>0</td>
      <td>175</td>
      <td>1</td>
      <td>224.976542</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>SARAI</td>
      <td>175</td>
      <td>2019</td>
      <td>20.284731</td>
      <td>122.202046</td>
      <td>0.0</td>
      <td>11.333333</td>
      <td>0.0</td>
      <td>2019</td>
      <td>15.700000</td>
      <td>4.856250</td>
      <td>176.85E_-17.15N</td>
      <td>86.0</td>
      <td>0</td>
      <td>175</td>
      <td>1</td>
      <td>224.976542</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3703</th>
      <td>3703</td>
      <td>SARAI</td>
      <td>2701</td>
      <td>2019</td>
      <td>28.861931</td>
      <td>97.172675</td>
      <td>0.0</td>
      <td>6.500000</td>
      <td>0.0</td>
      <td>2019</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>181.75E_-19.85N</td>
      <td>71.4</td>
      <td>0</td>
      <td>2701</td>
      <td>1</td>
      <td>17774.293574</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3704</th>
      <td>3704</td>
      <td>TINO</td>
      <td>2701</td>
      <td>2020</td>
      <td>9.664967</td>
      <td>252.982657</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>2020</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>181.75E_-19.85N</td>
      <td>71.4</td>
      <td>0</td>
      <td>2701</td>
      <td>1</td>
      <td>17774.293574</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3705</th>
      <td>3705</td>
      <td>HAROLD</td>
      <td>2701</td>
      <td>2020</td>
      <td>32.093306</td>
      <td>62.764842</td>
      <td>0.0</td>
      <td>185.000000</td>
      <td>0.0</td>
      <td>2020</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>181.75E_-19.85N</td>
      <td>71.4</td>
      <td>0</td>
      <td>2701</td>
      <td>1</td>
      <td>17774.293574</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3706</th>
      <td>3706</td>
      <td>YASA</td>
      <td>2701</td>
      <td>2020</td>
      <td>36.540718</td>
      <td>34.441416</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>2020</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>181.75E_-19.85N</td>
      <td>71.4</td>
      <td>0</td>
      <td>2701</td>
      <td>1</td>
      <td>17774.293574</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3707</th>
      <td>3707</td>
      <td>ANA</td>
      <td>2701</td>
      <td>2021</td>
      <td>0.000000</td>
      <td>335.268400</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>2021</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>181.75E_-19.85N</td>
      <td>71.4</td>
      <td>0</td>
      <td>2701</td>
      <td>1</td>
      <td>17774.293574</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>3708 rows × 20 columns</p>
</div>



### Baseline dummy model


```python
rmse_dummy = []
rmse_bin_dummy = []

y_test_typhoon = []
y_pred_typhoon = []

for typhoon in typhoons:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def[:-1])

    """ PART 2: Dummy regressor """
    # create a dummy regressor
    dummy_reg = DummyRegressor(strategy="mean")

    # fit it on the training set
    dummy_reg.fit(X_train, y_train)

    # make predictions on the test set
    y_pred = dummy_reg.predict(X_test)
    # make predictions on the train set
    y_pred_train = dummy_reg.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon.append(y_test)
    y_pred_typhoon.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_dummy.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin.append(rmse_test)
        else:
            rmse_test_bin.append(np.nan)

    rmse_bin_dummy.append(rmse_test_bin)
```

#### Dummy model results


```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon[i], y_pred_typhoon[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)
plt.suptitle('Dummy model using LOOCV \n(it always predict the mean value of the damage)')
plt.tight_layout()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_18_0.png)




```python
#total RMSE
print('dummy_mean_RMSE_total: ', np.nanmean(rmse_dummy))
```

    dummy_mean_RMSE_total:  0.23729860451646964



```python
rmse_strat_dummy = []
for i in range(num_bins):
    dummy_test_rmse_bin = np.nanmean(np.array(rmse_bin_dummy)[:,i])
    rmse_strat_dummy.append(dummy_test_rmse_bin)
#rmse_strat_dummy
```


```python
plt.plot(range(num_bins), rmse_strat_dummy, 'bs')
plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('Baseline model')
plt.grid()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_21_0.png)



### Linear Regressor


```python
from sklearn.linear_model import LinearRegression
rmse_linreg = []
rmse_bin_linreg = []

y_test_typhoon_linreg = []
y_pred_typhoon_linreg = []

for typhoon in typhoons:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def[:-1])

    """ PART 2: Linear regressor """
    # create a dummy regressor
    reg = LinearRegression()

    # fit it on the training set
    reg.fit(X_train, y_train)

    # make predictions on the test set
    y_pred = reg.predict(X_test)
    # make predictions on the train set
    y_pred_train = reg.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon_linreg.append(y_test)
    y_pred_typhoon_linreg.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_linreg.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin_linreg = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin_linreg.append(rmse_test)
        else:
            rmse_test_bin_linreg.append(np.nan)

    rmse_bin_linreg.append(rmse_test_bin_linreg)
```

#### Linear Regressor results


```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon_linreg[i], y_pred_typhoon_linreg[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)

plt.suptitle('Linear Regression using LOOCV')
plt.tight_layout()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_25_0.png)




```python
#total RMSE
print('LinReg_mean_RMSE_total: ', np.nanmean(rmse_linreg))
```

    LinReg_mean_RMSE_total:  0.24797212898801663



```python
rmse_strat_linreg = []
for i in range(num_bins):
    test_rmse_bin = np.nanmean(np.array(rmse_bin_linreg)[:,i])
    rmse_strat_linreg.append(test_rmse_bin)
#rmse_strat_linreg
```


```python
plt.plot(range(num_bins), rmse_strat_linreg, 'bs')
plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('Linear regression model')
plt.grid()
plt.show()

```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_28_0.png)



### XGBoost


```python
from xgboost.sklearn import XGBRegressor
rmse_xgb = []
rmse_bin_xgb = []

y_test_typhoon_xgb  = []
y_pred_typhoon_xgb  = []

for typhoon in typhoons:

    """ PART 1: Train/Test """
    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins_def[:-1])
    bin_index_train = np.digitize(y_train, bins=bins_def[:-1])

    """ PART 2: Linear regressor """
    # create an XGBoost Regressor
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )


    # fit it on the training set
    eval_set = [(X_train, y_train)]
    xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False) #xgb_model

    # make predictions on the test set
    y_pred = xgb.predict(X_test)
    # make predictions on the train set
    y_pred_train = xgb.predict(X_train)

    # Save y_test y_pred
    y_test_typhoon_xgb.append(y_test)
    y_pred_typhoon_xgb.append(y_pred)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred)
    rmse_test = np.sqrt(mse_test)
    rmse_xgb.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin_xgb = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin_xgb.append(rmse_test)
        else:
            rmse_test_bin_xgb.append(np.nan)

    rmse_bin_xgb.append(rmse_test_bin_xgb)
```

#### XGBoost regressor results


```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon_xgb[i], y_pred_typhoon_xgb[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)

plt.suptitle('XGBoost Regression using LOOCV')
plt.tight_layout()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_32_0.png)




```python
#total RMSE
print('XGB_mean_RMSE_total: ', np.nanmean(rmse_xgb))
```

    XGB_mean_RMSE_total:  0.29077409594566334



```python
rmse_strat_xgb = []
for i in range(num_bins):
    test_rmse_bin = np.nanmean(np.array(rmse_bin_xgb)[:,i])
    rmse_strat_xgb.append(test_rmse_bin)
#rmse_strat_xgb
```


```python
plt.plot(range(num_bins), rmse_strat_xgb, 'bs')
plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('XGBoost Regression model')
plt.grid()
plt.show()

```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_35_0.png)



### XGBOOST classifier


```python
thres = 3 # Damage threshold
df[df.percent_houses_damaged >= thres]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>typhoon_name</th>
      <th>grid_point_id</th>
      <th>typhoon_year_x</th>
      <th>wind_speed</th>
      <th>track_distance</th>
      <th>total_buildings_x</th>
      <th>total_buildings_damaged</th>
      <th>percent_houses_damaged</th>
      <th>typhoon_year_y</th>
      <th>rainfall_max_6h</th>
      <th>rainfall_max_24h</th>
      <th>Centroid</th>
      <th>IWI</th>
      <th>total_houses</th>
      <th>id</th>
      <th>with_coast</th>
      <th>coast_length</th>
      <th>mean_altitude</th>
      <th>mean_slope</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>308</th>
      <td>308</td>
      <td>WINSTON</td>
      <td>486</td>
      <td>2016</td>
      <td>54.922953</td>
      <td>18.896682</td>
      <td>15721.0</td>
      <td>7735.0</td>
      <td>3.695402</td>
      <td>2016</td>
      <td>0.066667</td>
      <td>0.018750</td>
      <td>177.45E_-17.65N</td>
      <td>86.0</td>
      <td>15721</td>
      <td>486</td>
      <td>1</td>
      <td>24414.711690</td>
      <td>110.060957</td>
      <td>70.804054</td>
    </tr>
    <tr>
      <th>978</th>
      <td>978</td>
      <td>HAROLD</td>
      <td>807</td>
      <td>2020</td>
      <td>42.992071</td>
      <td>19.785665</td>
      <td>628.0</td>
      <td>1578.0</td>
      <td>3.521242</td>
      <td>2020</td>
      <td>2.541667</td>
      <td>1.177083</td>
      <td>178.05E_-19.15N</td>
      <td>71.4</td>
      <td>628</td>
      <td>807</td>
      <td>1</td>
      <td>43033.688427</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>992</th>
      <td>992</td>
      <td>WINSTON</td>
      <td>840</td>
      <td>2016</td>
      <td>67.175189</td>
      <td>10.014419</td>
      <td>5041.0</td>
      <td>3570.0</td>
      <td>8.994541</td>
      <td>2016</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>178.15E_-17.35N</td>
      <td>73.0</td>
      <td>5041</td>
      <td>840</td>
      <td>1</td>
      <td>49042.568466</td>
      <td>146.172840</td>
      <td>74.163409</td>
    </tr>
    <tr>
      <th>1010</th>
      <td>1010</td>
      <td>WINSTON</td>
      <td>842</td>
      <td>2016</td>
      <td>71.993972</td>
      <td>12.145931</td>
      <td>1748.0</td>
      <td>3570.0</td>
      <td>3.118916</td>
      <td>2016</td>
      <td>0.025000</td>
      <td>0.006250</td>
      <td>178.15E_-17.55N</td>
      <td>73.0</td>
      <td>1748</td>
      <td>842</td>
      <td>0</td>
      <td>0.000000</td>
      <td>439.198302</td>
      <td>81.780565</td>
    </tr>
    <tr>
      <th>1113</th>
      <td>1113</td>
      <td>HAROLD</td>
      <td>857</td>
      <td>2020</td>
      <td>48.011328</td>
      <td>5.389440</td>
      <td>932.0</td>
      <td>1578.0</td>
      <td>5.225792</td>
      <td>2020</td>
      <td>2.633333</td>
      <td>1.279167</td>
      <td>178.15E_-19.05N</td>
      <td>71.4</td>
      <td>932</td>
      <td>857</td>
      <td>1</td>
      <td>62351.916992</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1365</th>
      <td>1365</td>
      <td>HAROLD</td>
      <td>959</td>
      <td>2020</td>
      <td>40.759318</td>
      <td>2.712904</td>
      <td>544.0</td>
      <td>1578.0</td>
      <td>3.050248</td>
      <td>2020</td>
      <td>3.475000</td>
      <td>1.418750</td>
      <td>178.35E_-19.05N</td>
      <td>71.4</td>
      <td>544</td>
      <td>959</td>
      <td>1</td>
      <td>47576.589235</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1482</th>
      <td>1482</td>
      <td>HAROLD</td>
      <td>1009</td>
      <td>2020</td>
      <td>38.467699</td>
      <td>17.109128</td>
      <td>566.0</td>
      <td>1578.0</td>
      <td>3.173603</td>
      <td>2020</td>
      <td>3.783333</td>
      <td>1.329167</td>
      <td>178.45E_-18.95N</td>
      <td>71.4</td>
      <td>566</td>
      <td>1009</td>
      <td>1</td>
      <td>60343.175054</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1802</th>
      <td>1802</td>
      <td>WINSTON</td>
      <td>1149</td>
      <td>2016</td>
      <td>77.863256</td>
      <td>28.310424</td>
      <td>990.0</td>
      <td>1487.0</td>
      <td>3.268675</td>
      <td>2016</td>
      <td>0.200000</td>
      <td>0.054167</td>
      <td>178.75E_-17.65N</td>
      <td>71.4</td>
      <td>990</td>
      <td>1149</td>
      <td>1</td>
      <td>28137.720769</td>
      <td>0.007716</td>
      <td>0.054837</td>
    </tr>
    <tr>
      <th>1892</th>
      <td>1892</td>
      <td>WINSTON</td>
      <td>1200</td>
      <td>2016</td>
      <td>74.273432</td>
      <td>30.136886</td>
      <td>1286.0</td>
      <td>1487.0</td>
      <td>4.245975</td>
      <td>2016</td>
      <td>0.083333</td>
      <td>0.022917</td>
      <td>178.85E_-17.65N</td>
      <td>71.4</td>
      <td>1286</td>
      <td>1200</td>
      <td>1</td>
      <td>19932.444313</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2275</th>
      <td>2275</td>
      <td>YASA</td>
      <td>1443</td>
      <td>2020</td>
      <td>38.140583</td>
      <td>36.663163</td>
      <td>9963.0</td>
      <td>4021.0</td>
      <td>9.805340</td>
      <td>2020</td>
      <td>1.825000</td>
      <td>0.595833</td>
      <td>179.35E_-16.45N</td>
      <td>85.4</td>
      <td>9963</td>
      <td>1443</td>
      <td>1</td>
      <td>12306.788561</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2459</th>
      <td>2459</td>
      <td>WINSTON</td>
      <td>1503</td>
      <td>2016</td>
      <td>77.051178</td>
      <td>12.421345</td>
      <td>969.0</td>
      <td>1487.0</td>
      <td>3.199339</td>
      <td>2016</td>
      <td>0.441667</td>
      <td>0.118750</td>
      <td>179.45E_-17.35N</td>
      <td>71.4</td>
      <td>969</td>
      <td>1503</td>
      <td>1</td>
      <td>20750.588556</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from matplotlib import cm
from mlxtend.plotting import plot_confusion_matrix

cms = []
accuracy =[]

for typhoon in typhoons:

    """      STEP 0: TRAIN TEST SPLIT LOOCV     """

    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    """      STEP 1: XGB CLASSIFIER     """
    # Define a threshold to separate target into damaged and not_damaged
    y_test_bool = y_test >= thres
    y_train_bool = y_train >= thres
    y_test_bin = (y_test_bool) * 1 #nice way to concert boolean to binary
    y_train_bin = (y_train_bool) * 1


    # Use XGBClassifier as a Machine Learning model to fit the data
    xgb_model = XGBClassifier(eval_metric=["error", "logloss"])
    eval_set = [(X_test, y_test_bin)]
    xgb_model.fit(X_train,y_train_bin,eval_set=eval_set,verbose=False)

    # Make prediction on test data
    y_pred_test = xgb_model.predict(X_test)
    # Make prediction on train data
    y_pred_train = xgb_model.predict(X_train)

    # Accuracy
    acc = accuracy_score(y_test_bin, y_pred_test)
    accuracy.append(acc)

    # Confussion matrix
    cm = confusion_matrix(y_test_bin, y_pred_test)
    cms.append(cm)
```


```python
# Total cm
overall_confusion_matrix = np.zeros((2, 2))
for confusion_matrix in cms:
    overall_confusion_matrix += confusion_matrix

# Plot Confusion Matrix
fig, ax = plot_confusion_matrix(
    conf_mat=overall_confusion_matrix,
    show_absolute=True,
    show_normed=False,
    colorbar=False,
    cmap=plt.cm.Greens,
)
ax.set_xlabel('')
ax.set_ylabel('')
ax.xaxis.set(ticks=(0, 1), ticklabels=("Predicted 0s", "Predicted 1s"))
ax.yaxis.set(ticks=(0, 1), ticklabels=("Actual 0s", "Actual 1s"))
ax.set_title("Confusion Matrix for XGBoost Model\nthreshold = {} %".format(thres))
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_39_0.png)




```python
# Accuracy
print('XGB-Classifier Accuracy: {}'.format(np.mean(accuracy)))
```

    XGB-Classifier Accuracy: 0.9897518878101403


### 2SG_XGB


```python
thres = 3 # Damage threshold
df[df.percent_houses_damaged >= thres]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>typhoon_name</th>
      <th>grid_point_id</th>
      <th>typhoon_year_x</th>
      <th>wind_speed</th>
      <th>track_distance</th>
      <th>total_buildings_x</th>
      <th>total_buildings_damaged</th>
      <th>percent_houses_damaged</th>
      <th>typhoon_year_y</th>
      <th>rainfall_max_6h</th>
      <th>rainfall_max_24h</th>
      <th>Centroid</th>
      <th>IWI</th>
      <th>total_houses</th>
      <th>id</th>
      <th>with_coast</th>
      <th>coast_length</th>
      <th>mean_altitude</th>
      <th>mean_slope</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>308</th>
      <td>308</td>
      <td>WINSTON</td>
      <td>486</td>
      <td>2016</td>
      <td>54.922953</td>
      <td>18.896682</td>
      <td>15721.0</td>
      <td>7735.0</td>
      <td>3.695402</td>
      <td>2016</td>
      <td>0.066667</td>
      <td>0.018750</td>
      <td>177.45E_-17.65N</td>
      <td>86.0</td>
      <td>15721</td>
      <td>486</td>
      <td>1</td>
      <td>24414.711690</td>
      <td>110.060957</td>
      <td>70.804054</td>
    </tr>
    <tr>
      <th>978</th>
      <td>978</td>
      <td>HAROLD</td>
      <td>807</td>
      <td>2020</td>
      <td>42.992071</td>
      <td>19.785665</td>
      <td>628.0</td>
      <td>1578.0</td>
      <td>3.521242</td>
      <td>2020</td>
      <td>2.541667</td>
      <td>1.177083</td>
      <td>178.05E_-19.15N</td>
      <td>71.4</td>
      <td>628</td>
      <td>807</td>
      <td>1</td>
      <td>43033.688427</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>992</th>
      <td>992</td>
      <td>WINSTON</td>
      <td>840</td>
      <td>2016</td>
      <td>67.175189</td>
      <td>10.014419</td>
      <td>5041.0</td>
      <td>3570.0</td>
      <td>8.994541</td>
      <td>2016</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>178.15E_-17.35N</td>
      <td>73.0</td>
      <td>5041</td>
      <td>840</td>
      <td>1</td>
      <td>49042.568466</td>
      <td>146.172840</td>
      <td>74.163409</td>
    </tr>
    <tr>
      <th>1010</th>
      <td>1010</td>
      <td>WINSTON</td>
      <td>842</td>
      <td>2016</td>
      <td>71.993972</td>
      <td>12.145931</td>
      <td>1748.0</td>
      <td>3570.0</td>
      <td>3.118916</td>
      <td>2016</td>
      <td>0.025000</td>
      <td>0.006250</td>
      <td>178.15E_-17.55N</td>
      <td>73.0</td>
      <td>1748</td>
      <td>842</td>
      <td>0</td>
      <td>0.000000</td>
      <td>439.198302</td>
      <td>81.780565</td>
    </tr>
    <tr>
      <th>1113</th>
      <td>1113</td>
      <td>HAROLD</td>
      <td>857</td>
      <td>2020</td>
      <td>48.011328</td>
      <td>5.389440</td>
      <td>932.0</td>
      <td>1578.0</td>
      <td>5.225792</td>
      <td>2020</td>
      <td>2.633333</td>
      <td>1.279167</td>
      <td>178.15E_-19.05N</td>
      <td>71.4</td>
      <td>932</td>
      <td>857</td>
      <td>1</td>
      <td>62351.916992</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1365</th>
      <td>1365</td>
      <td>HAROLD</td>
      <td>959</td>
      <td>2020</td>
      <td>40.759318</td>
      <td>2.712904</td>
      <td>544.0</td>
      <td>1578.0</td>
      <td>3.050248</td>
      <td>2020</td>
      <td>3.475000</td>
      <td>1.418750</td>
      <td>178.35E_-19.05N</td>
      <td>71.4</td>
      <td>544</td>
      <td>959</td>
      <td>1</td>
      <td>47576.589235</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1482</th>
      <td>1482</td>
      <td>HAROLD</td>
      <td>1009</td>
      <td>2020</td>
      <td>38.467699</td>
      <td>17.109128</td>
      <td>566.0</td>
      <td>1578.0</td>
      <td>3.173603</td>
      <td>2020</td>
      <td>3.783333</td>
      <td>1.329167</td>
      <td>178.45E_-18.95N</td>
      <td>71.4</td>
      <td>566</td>
      <td>1009</td>
      <td>1</td>
      <td>60343.175054</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1802</th>
      <td>1802</td>
      <td>WINSTON</td>
      <td>1149</td>
      <td>2016</td>
      <td>77.863256</td>
      <td>28.310424</td>
      <td>990.0</td>
      <td>1487.0</td>
      <td>3.268675</td>
      <td>2016</td>
      <td>0.200000</td>
      <td>0.054167</td>
      <td>178.75E_-17.65N</td>
      <td>71.4</td>
      <td>990</td>
      <td>1149</td>
      <td>1</td>
      <td>28137.720769</td>
      <td>0.007716</td>
      <td>0.054837</td>
    </tr>
    <tr>
      <th>1892</th>
      <td>1892</td>
      <td>WINSTON</td>
      <td>1200</td>
      <td>2016</td>
      <td>74.273432</td>
      <td>30.136886</td>
      <td>1286.0</td>
      <td>1487.0</td>
      <td>4.245975</td>
      <td>2016</td>
      <td>0.083333</td>
      <td>0.022917</td>
      <td>178.85E_-17.65N</td>
      <td>71.4</td>
      <td>1286</td>
      <td>1200</td>
      <td>1</td>
      <td>19932.444313</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2275</th>
      <td>2275</td>
      <td>YASA</td>
      <td>1443</td>
      <td>2020</td>
      <td>38.140583</td>
      <td>36.663163</td>
      <td>9963.0</td>
      <td>4021.0</td>
      <td>9.805340</td>
      <td>2020</td>
      <td>1.825000</td>
      <td>0.595833</td>
      <td>179.35E_-16.45N</td>
      <td>85.4</td>
      <td>9963</td>
      <td>1443</td>
      <td>1</td>
      <td>12306.788561</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2459</th>
      <td>2459</td>
      <td>WINSTON</td>
      <td>1503</td>
      <td>2016</td>
      <td>77.051178</td>
      <td>12.421345</td>
      <td>969.0</td>
      <td>1487.0</td>
      <td>3.199339</td>
      <td>2016</td>
      <td>0.441667</td>
      <td>0.118750</td>
      <td>179.45E_-17.35N</td>
      <td>71.4</td>
      <td>969</td>
      <td>1503</td>
      <td>1</td>
      <td>20750.588556</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
from xgboost import XGBClassifier
rmse_combined = []
rmse_bin_combined = []

y_test_typhoon_combined = []
y_pred_typhoon_combined = []

i=0
for typhoon in typhoons:

    """      STEP 0: TRAIN TEST SPLIT      """

    # Split X and y from dataframe features
    X = df[features]
    y = df["percent_houses_damaged"]

    # Split df to train and test (one typhoon for test and the rest of typhoons for train) --LOOCV--
    df_test = df[df["typhoon_name"] == typhoon]
    df_train = df[df["typhoon_name"] != typhoon]

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    print('{}/{} '.format(i+1, len(typhoons)),typhoon)
    i+=1

    """      STEP 1: M-model (510 model)      """

    # XGBoost Reduced Overfitting
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )

    eval_set = [(X_train, y_train)]
    xgb_model = xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False)

    # Make prediction on train and test data
    y_pred_train = xgb.predict(X_train)
    y_pred = xgb.predict(X_test)

    # Calculate RMSE in total
    mse_train_idx = mean_squared_error(y_train, y_pred_train)
    rmse_train = np.sqrt(mse_train_idx)

    mse_idx = mean_squared_error(y_test, y_pred)
    rmseM1 = np.sqrt(mse_idx)

    """      STEP 2: 2SG-Model part 1, Classifier      """

    # Define a threshold to separate target into damaged and not_damaged
    y_test_bool = y_test >= thres
    y_train_bool = y_train >= thres
    y_test_bin = (y_test_bool) * 1 #nice way to concert boolean to binary
    y_train_bin = (y_train_bool) * 1


    # Use XGBClassifier as a Machine Learning model to fit the data
    xgb_model = XGBClassifier(eval_metric=["error", "logloss"])
    eval_set = [(X_test, y_test_bin)]
    xgb_model.fit(X_train,y_train_bin,eval_set=eval_set,verbose=False)

    # Make prediction on test data
    y_pred_test = xgb_model.predict(X_test)
    # Make prediction on train data
    y_pred_train = xgb_model.predict(X_train)


    # Create Reduced dataset (basically X_reduced = X_train + y_train)
    reduced_df = X_train.copy()
    reduced_df["percent_houses_damaged"] = y_train.values
    reduced_df["predicted_value"] = y_pred_train

    # Just Predicted Damage dataset
    fliterd_df = reduced_df[reduced_df.predicted_value == 1]

    """      STEP 3: 2SG-Model part 2, Regression      """

    ### Third step is to train XGBoost regression model for this reduced train data (including damg>10.0%)
    bin_index2 = np.digitize(fliterd_df["percent_houses_damaged"], bins=bins_def[-1:])
    y_input_strat2 = bin_index2

    # Split X and y from dataframe features (JUST WHEN predicted_value == 1, i.e fliterd_df)
    X_r = fliterd_df[features]
    y_r = fliterd_df["percent_houses_damaged"]

    # XGBoost Reduced Overfitting
    xgbR = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )

    eval_set = [(X_r, y_r)]
    xgbR_model = xgbR.fit(X_r, y_r, eval_set=eval_set, verbose=False)

    # Make prediction on train and global test data
    y_pred_r = xgbR.predict(X_r)
    y_pred_test_total = xgbR.predict(X_test)

    # Calculate RMSE in total
    mse_train_idxR = mean_squared_error(y_r, y_pred_r)
    rmse_trainR = np.sqrt(mse_train_idxR)

    mse_idxR = mean_squared_error(y_test, y_pred_test_total)
    rmseR = np.sqrt(mse_idxR)

    """      STEP 4: 2SG-Model part 3, All together      """

    ## Last step is to add model combination (model M1 with model MR)
    # Check the result of classifier for TEST SET
    reduced_test_df = X_test.copy()

    # joined X_test with countinous target and binary predicted values with Classificator XGB (step 2)
    reduced_test_df["percent_houses_damaged"] = y_test.values
    reduced_test_df["predicted_value"] = y_pred_test

    # damaged prediction
    fliterd_test_df1 = reduced_test_df[reduced_test_df.predicted_value == 1]
    # not damaged prediction
    fliterd_test_df0 = reduced_test_df[reduced_test_df.predicted_value == 0]

    # keep only the features
    X1 = fliterd_test_df1[features] #just damage
    X0 = fliterd_test_df0[features] #not damage

    # For the output equal to 1 apply XGBReg (step 3) to evaluate the performance
    y1_pred = xgbR.predict(X1)
    y1 = fliterd_test_df1["percent_houses_damaged"]

    # For the output equal to 0 apply XGBReg (M1-Model -510 model- of step 1) to evaluate the performance
    y0_pred = xgb.predict(X0)
    y0 = fliterd_test_df0["percent_houses_damaged"]

    fliterd_test_df0["predicted_percent_damage"] = y0_pred
    fliterd_test_df1["predicted_percent_damage"] = y1_pred

    # Join two dataframes together
    join_test_dfs = pd.concat([fliterd_test_df0, fliterd_test_df1])

    """      STEP 5: 2SG-Model part 4, Calculate final stuff      """

    # Calculate RMSE in total
    mse_combined_model = mean_squared_error(
        join_test_dfs["percent_houses_damaged"],
        join_test_dfs["predicted_percent_damage"],
    )

    rmse_combined_model = np.sqrt(mse_combined_model)
    rmse_combined.append(rmse_combined_model)

    # Calculate RMSE per bin
    y_join = join_test_dfs["percent_houses_damaged"]
    y_pred_join = join_test_dfs["predicted_percent_damage"]

    y_test_typhoon_combined.append(y_join)
    y_pred_typhoon_combined.append(y_pred_join)

    # Per bin
    bin_index_test = np.digitize(y_join, bins=bins_def[:-1])
    RSME_combined_model = []
    for bin_num in range(num_bins+1)[1:]:
        if (len(y_join[bin_index_test == bin_num]) != 0 and len(y_pred_join[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(
                y_join[bin_index_test == bin_num],
                y_pred_join[bin_index_test == bin_num],
            )
            rmse_test = np.sqrt(mse_test)
            RSME_combined_model.append(rmse_test)
        else:
           RSME_combined_model.append(np.nan)


    rmse_bin_combined.append(RSME_combined_model)
```

    1/9  TOMAS
    2/9  EVAN
    3/9  WINSTON


    /var/folders/dy/vms3cfrn4q9952h8s6l586dr0000gp/T/ipykernel_95176/3728434277.py:188: SettingWithCopyWarning:
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      fliterd_test_df0["predicted_percent_damage"] = y0_pred
    /var/folders/dy/vms3cfrn4q9952h8s6l586dr0000gp/T/ipykernel_95176/3728434277.py:189: SettingWithCopyWarning:
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      fliterd_test_df1["predicted_percent_damage"] = y1_pred


    4/9  GITA
    5/9  SARAI
    6/9  TINO
    7/9  HAROLD
    8/9  YASA
    9/9  ANA


    /var/folders/dy/vms3cfrn4q9952h8s6l586dr0000gp/T/ipykernel_95176/3728434277.py:188: SettingWithCopyWarning:
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      fliterd_test_df0["predicted_percent_damage"] = y0_pred
    /var/folders/dy/vms3cfrn4q9952h8s6l586dr0000gp/T/ipykernel_95176/3728434277.py:189: SettingWithCopyWarning:
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      fliterd_test_df1["predicted_percent_damage"] = y1_pred


#### 2SG-XGB Results


```python
fig, ax = plt.subplots(3,3, figsize=(10,10))
ax = ax.flatten()
for i, typhoon in enumerate(typhoons):
    ax[i].plot(y_test_typhoon_combined[i], y_pred_typhoon_combined[i], 'o')
    ax[i].set_title('Test: {}'.format(typhoon))
ax[3].set_ylabel('y pred [% of damage]', size=20)
ax[7].set_xlabel('y test [% of damage]', size=20)

plt.suptitle('2SG-XGBoost Regression using LOOCV')
plt.tight_layout()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_45_0.png)




```python
#total RMSE
print('2SG-XGB_mean_RMSE_total: ', np.nanmean(rmse_combined))
```

    2SG-XGB_mean_RMSE_total:  0.42074998705206945



```python
rmse_strat_combined = []
for i in range(num_bins):
    test_rmse_bin = np.nanmean(np.array(rmse_bin_combined)[:,i])
    rmse_strat_combined.append(test_rmse_bin)
#rmse_strat_combined
```


```python
plt.plot(range(num_bins), rmse_strat_combined, 'bs')
plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('2SG-XGBoost model')
plt.grid()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_48_0.png)



### Models comparison


```python
total_rmse_xgb = np.round(np.nanmean(rmse_xgb),3)
total_rmse_lin = np.round(np.nanmean(rmse_linreg),3)
total_rmse_dum = np.round(np.nanmean(rmse_dummy),3)
total_rmse_comb = np.round(np.nanmean(rmse_combined),3)
plt.plot(range(num_bins), rmse_strat_xgb, 'bo', alpha=0.9, label='XGBoost Regression model\nTotal Rmse: {}'.format(total_rmse_xgb))
plt.plot(range(num_bins), rmse_strat_linreg, 'ro', alpha=0.9, label='Linear regression model\nTotal Rmse: {}'.format(total_rmse_lin))
plt.plot(range(num_bins), rmse_strat_dummy, 'go', alpha=0.9, label='Baseline model\nTotal Rmse: {}'.format(total_rmse_dum))
plt.plot(range(num_bins), rmse_strat_combined, 'k*', alpha=0.5, label='2SG-XGBoost model\nTotal Rmse: {}'.format(total_rmse_comb))


plt.xticks(range(num_bins), str_bin, rotation=45)
plt.xlabel('Damage [%]')
plt.ylabel('RMSE')
plt.title('RMSE per bin')
plt.grid()
plt.legend()
plt.show()
```



![png](02.0_model_training-baselines_files/02.0_model_training-baselines_50_0.png)
