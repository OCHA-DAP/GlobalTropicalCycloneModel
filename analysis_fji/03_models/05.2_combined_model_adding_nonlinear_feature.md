```python
import matplotlib.pyplot as plt
from matplotlib.colors import Normalize
import matplotlib.patches as mpatches
import numpy as np
import os
from pathlib import Path
import pandas as pd
import geopandas as gpd
# import shap
from sklearn.metrics import mean_squared_error
from xgboost.sklearn import XGBRegressor

from climada.hazard import Centroids, TCTracks, TropCyclone
from shapely.geometry import LineString

from utils import get_combined_dataset, xgb_model_combined_data_LOOCV, get_training_dataset_complete, get_municipality_grids
```


```python
# Load dataset
df_combined = get_combined_dataset()
df_combined_classic = df_combined.copy() # Store the precious approach (without adding the feature)

# Add feature r^0.5
df_combined['track_distance_root'] = df_combined['track_distance'] ** 0.5

df_fji = df_combined[df_combined.country == 'fji']
df_fji_classic = df_combined_classic[df_combined_classic.country == 'fji']

# Typhoons
fji_typhoons = df_fji.typhoon_name.unique()

# Features
features = [
    "wind_speed",
    "track_distance",
    "total_houses",
    "rainfall_max_6h",
    "rainfall_max_24h",
    "coast_length",
    "with_coast",
    "mean_elev",
    "mean_slope",
    "track_distance_root"
]

features_classic = [
    "wind_speed",
    "track_distance",
    "total_houses",
    "rainfall_max_6h",
    "rainfall_max_24h",
    "coast_length",
    "with_coast",
    "mean_elev",
    "mean_slope",
]

# Load Fiji complete
df_fji_complete = get_training_dataset_complete()
df_fji_complete = df_fji_complete[df_fji_complete.typhoon_name != 'ANA'] # Drop ANA
# Add feature r^0.5
df_fji_complete['track_distance_root'] = df_fji_complete['track_distance'] ** 0.5
df_fji_complete = df_fji_complete.rename({
    "mean_altitude": "mean_elev",
    "total_buildings": "total_houses"
}, axis=1)
df_fji_complete = df_fji_complete[features + ['typhoon_name', 'grid_point_id', 'Centroid', 'perc_dmg_grid']]

# Load Fiji Shapefile
input_dir = (
    Path(os.getenv("STORM_DATA_DIR"))
    / "analysis_fji/02_model_features/02_housing_damage/input/"
)
fiji = gpd.read_file(
    input_dir / "adm2_shp_fixed.gpkg"
)
fiji = fiji.to_crs('EPSG:4326')

# Load real damage
actual_mun_dmg = pd.read_csv(input_dir / "fji_building_damage_mun_complete.csv")
actual_mun_dmg['typhoon'] = actual_mun_dmg['typhoon'].str.upper()

# Load typhoon track
tracks_dir = (
    Path(os.getenv("STORM_DATA_DIR"))
    / "analysis_fji/02_model_features/01_windfield"
)
typhoons_info = pd.read_csv(tracks_dir / "typhoons.csv")
typhoons_info.typhoon_name = typhoons_info.typhoon_name.str.upper()
cyclones = actual_mun_dmg['typhoon'].unique()
intersection = typhoons_info[typhoons_info['typhoon_name'].isin(cyclones)].drop_duplicates(keep='last', subset = ['typhoon_name'])
```


```python
# Stratification
dmg = np.array(df_fji.percent_houses_damaged.to_list())
zero_dmg = np.round((np.count_nonzero(dmg == 0) / len(dmg)) , 2 )

# Define ranges for each group
x0 = list(np.linspace(0, zero_dmg, 1))   # zero damage
x1 = list(np.linspace(zero_dmg, 0.93, 2))  # almost no damage
x2 = list(np.linspace(0.935, 1, 5))  # all the damage
x3=x0+x1+x2

bins = []
for i in x3:
    bins.append(np.quantile(dmg, i))

# Histogram after stratification
samples_per_bin_fji, bins_def_fji = np.histogram(dmg, bins=bins)

# Define number of bins
num_bins_fji = len(samples_per_bin_fji)

# For future plots
str_bin_fji = []
for i in range(len(bins_def_fji[:-1])):
    a = str(np.round(bins_def_fji[i+1],3))
    b = str(np.round(bins_def_fji[i],3))
    str_bin_fji.append('{} - {}'.format(b,a))
```


```python
# Drop ANA typhoon
df_combined_noana = df_combined[df_combined.typhoon_name != 'ANA']
df_fji_noana= df_fji[df_fji.typhoon_name != 'ANA']
fji_typhoons = df_fji_noana.typhoon_name.unique()

df_combined_noana_classic = df_combined_classic[df_combined.typhoon_name != 'ANA']
df_fji_noana_classic = df_fji_classic[df_fji_classic.typhoon_name != 'ANA']
```


```python
# Run XGB with and without this new feature

# WITH new feature
y_test_typhoon, y_pred_typhoon, rmse_strat, avg_error_strat = xgb_model_combined_data_LOOCV(
    df_combined=df_combined_noana,
    df_fji=df_fji_noana,
    bins=bins_def_fji,
    fji_weight=6,
    features=features
)

# WITHOUT new feature
y_test_typhoon_classic, y_pred_typhoon_classic, rmse_strat_classic, avg_error_strat_classic = xgb_model_combined_data_LOOCV(
    df_combined=df_combined_noana_classic,
    df_fji=df_fji_noana_classic,
    bins=bins_def_fji,
    fji_weight=6,
    features=features_classic
)
```


```python
fig, ax = plt.subplots(1,1, figsize=(6,6))

ax.plot(range(num_bins_fji), rmse_strat, 'bs', label='Add new feature')
ax.plot(range(num_bins_fji), rmse_strat_classic, 'gs', label='Classic features')

ax.set_xticks(range(num_bins_fji), str_bin_fji, rotation=45)
ax.set_xlabel('Damage [%]')
ax.set_ylabel('RMSE')
ax.grid()
ax.set_title('XGBoost Regression model trained on Philippines+Fiji \ndataset using LOOCV for Fiji typhoons')
ax.legend()

plt.tight_layout()
plt.show()
```



![png](05.2_combined_model_adding_nonlinear_feature_files/05.2_combined_model_adding_nonlinear_feature_5_0.png)



## Results at municipality level


```python
# Results at municipality level
typhoon='WINSTON'

# Calculate buildings destroyed by municipality and % of buildings destroyed by mun
mun_id = get_municipality_grids()[['id','NAME_2']]
def num_bld_destroyed_mun(mun, typhoon, real = False):

    k = fji_typhoons.tolist().index(typhoon)
    df_typhoon = df_fji_complete[df_fji_complete.typhoon_name==typhoon]
    # Add feature "predictive_damage"
    df_typhoon['predicted_damage'] = y_pred_typhoon[k]

    mun_ids = mun_id[mun_id.NAME_2 == mun].id.to_list()
    cells_in_mun = df_typhoon[df_typhoon.typhoon_name == typhoon].set_index('grid_point_id').loc[mun_ids]

    if real:
        damage_grid = np.array(cells_in_mun.perc_dmg_grid.to_list()) # Real dmg
    else:
        damage_grid = np.array(cells_in_mun.predicted_damage.to_list()) # Dmg predicted by cell

    # Number of buildings
    N_bld_grid = np.array(cells_in_mun.total_houses.to_list()) # Bld by cell
    N_bld_mun = np.sum(N_bld_grid) # Total bld in mun

    # Calculate % of buildings (and N of bld) destroyed by mun
    N_bld_dest_pred_mun = np.sum(damage_grid) * (N_bld_mun / 100)
    perc_destroyed_mun = np.sum(damage_grid)

    return N_bld_dest_pred_mun, perc_destroyed_mun

# Create new features in shapefile with predicted and real damage
def calculate_actual_perc_dmg(x, i):
    try:
        return num_bld_destroyed_mun(mun=x['NAME_2'], typhoon=typhoon, real=True)[i]
    except:
        return 0
def calculate_pred_perc_dmg(x, i):
    try:
        return num_bld_destroyed_mun(mun=x['NAME_2'], typhoon=typhoon, real=False)[i]
    except:
        return 0
fiji['actual_perc_dmg'] = fiji.apply(calculate_actual_perc_dmg, i=1, axis=1)
fiji['actual_bld_dest'] = fiji.apply(calculate_actual_perc_dmg, i=0, axis=1)
fiji['pred_perc_dmg'] = fiji.apply(calculate_pred_perc_dmg, i=1, axis=1)
fiji['pred_bld_dmg'] = fiji.apply(calculate_pred_perc_dmg, i=0, axis=1)
fiji['prediction_error'] = fiji['actual_perc_dmg'] - fiji['pred_perc_dmg'] # in percentual points

# Load track
id = intersection[intersection['typhoon_name'] == typhoon].typhoon_id.to_list()
track = TCTracks.from_ibtracs_netcdf(storm_id=id)
tc_track = track.get_track()

points_ib = gpd.points_from_xy(tc_track.lon, tc_track.lat)
tc_track_line_ib = LineString(points_ib)

geometries_ib = gpd.GeoSeries([tc_track_line_ib])
line_gdf_ib = gpd.GeoDataFrame(geometry=geometries_ib)

# Plot
# Plotting the data
cmap='Reds'
cmap_blue = 'Blues'
cmap_red = 'Reds_r'
fig, ax = plt.subplots(1, 3, figsize=(15, 5))
vmax = max([fiji.actual_perc_dmg.max(), fiji.pred_perc_dmg.max()])

# Check prediction_error column for values > 0 and < 0
positive_error = fiji[fiji['prediction_error'] > 0]
negative_error = fiji[fiji['prediction_error'] < 0]

# Plotting the maps
fiji_plot_1 = fiji.plot(column='actual_perc_dmg', cmap=cmap, linewidth=0.2, ax=ax[0], edgecolor='0.3', legend=True)
fiji_plot_2 = fiji.plot(column='pred_perc_dmg', cmap=cmap, linewidth=0.2, ax=ax[1], edgecolor='0.3', legend=True)
fiji_plot_3 = fiji.plot(column='prediction_error', cmap='Reds_r', linewidth=0.2, ax=ax[2], edgecolor='0.3', legend=True)
# fiji_plot_3_blue = positive_error.plot(column='prediction_error', cmap=cmap_blue, linewidth=0.2, ax=ax[2], edgecolor='0.3', legend=True, vmin=0)
# fiji_plot_3_red = negative_error.plot(column='prediction_error', cmap=cmap_red, linewidth=0.2, ax=ax[2], edgecolor='0.3', legend=True, vmax=0)


line_gdf_ib.plot(ax=ax[0], color='k', linewidth=1, label='Typhoon track')  # Plot the LineString in black
line_gdf_ib.plot(ax=ax[1], color='k', linewidth=1, label='Typhoon track')  # Plot the LineString in black
line_gdf_ib.plot(ax=ax[2], color='k', linewidth=1, label='Typhoon track')  # Plot the LineString in black

# Create custom legends
# blue_patch = mpatches.Patch(color='#6495ED', label='Underestimated damage')
# red_patch = mpatches.Patch(color='#800000', label='Overestimated damage')
# ax[2].legend(handles=[blue_patch, red_patch], loc='lower left', bbox_to_anchor=(-0.05, -0.2))

ax[0].set_title('Actual Damage by municipality')
ax[1].set_title('Predicted Damage by municipality')
ax[2].set_title('Prediction Error \n $actual_{dmg} - predicted_{dmg}$ \n(in percentage points)')
ax[0].axis('off')
ax[1].axis('off')
ax[2].axis('off')

# All Fiji map
ax[0].set_xlim(176, 182)
ax[0].set_ylim(-20, -12)
ax[1].set_xlim(176, 182)
ax[1].set_ylim(-20, -12)
ax[2].set_xlim(176, 182)
ax[2].set_ylim(-20, -12)

plt.suptitle('Typhoon {}'.format(typhoon), y=1.1)
plt.tight_layout()
plt.show()
```

    2023-12-11 20:37:29,154 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.




![png](05.2_combined_model_adding_nonlinear_feature_files/05.2_combined_model_adding_nonlinear_feature_7_1.png)



## Importance of this new feature


```python
""" THE MODEL (again)"""
bins=bins_def_fji
fji_weight=3

# Dataframe Fiji
fji_typhoons = df_fji.typhoon_name.unique()

# Bins
num_bins = len(bins)

# The model
rmse_total_fji = []
rmse_bin_fji = []
avg_error_bin_fji = []

y_test_typhoon_fji  = []
y_pred_typhoon_fji  = []
# Create an empty dictionary to store feature importances for each typhoon (each LOOCV iteration)
feature_importance_dict = {feature: [] for feature in features}
YASA_fi = []

for typhoon in fji_typhoons:

    """ PART 1: Train/Test """

    # LOOCV
    df_test = df_fji[df_fji["typhoon_name"] == typhoon] # Test set: Fiji
    df_train = df_combined[df_combined["typhoon_name"] != typhoon] # Train set: everything

    # Class weight
    weights = np.where(df_train['country'] == 'phl', 1, fji_weight) # Let's give more weight to Fiji

    # Split X and y from dataframe features
    X_test = df_test[features]
    X_train = df_train[features]

    y_train = df_train["percent_houses_damaged"]
    y_test = df_test["percent_houses_damaged"]

    # Stratify data
    bin_index_test = np.digitize(y_test, bins=bins[:-1])

    """ PART 2: XGB regressor """
    # create an XGBoost Regressor
    xgb = XGBRegressor(
        base_score=0.5,
        booster="gbtree",
        colsample_bylevel=0.8,
        colsample_bynode=0.8,
        colsample_bytree=0.8,
        gamma=3,
        eta=0.01,
        importance_type="gain",
        learning_rate=0.1,
        max_delta_step=0,
        max_depth=4,
        min_child_weight=1,
        missing=1,
        n_estimators=100,
        early_stopping_rounds=10,
        n_jobs=1,
        nthread=None,
        objective="reg:squarederror",
        reg_alpha=0,
        reg_lambda=1,
        scale_pos_weight=1,
        seed=None,
        silent=None,
        subsample=0.8,
        verbosity=0,
        eval_metric=["rmse", "logloss"],
        random_state=0,
    )

    # Fit the model
    eval_set = [(X_train, y_train)]
    xgb.fit(X_train, y_train, eval_set=eval_set, verbose=False, sample_weight=weights) #xgb_model

    # Get feature importance and append to dictionary
    feature_importance = xgb.feature_importances_
    for idx, feature in enumerate(features):
        feature_importance_dict[feature].append(feature_importance[idx])

    if typhoon == "YASA":
        YASA_fi.append(feature_importance)

    # make predictions on Fiji
    y_pred_fji = xgb.predict(X_test)

    # Save y_test y_pred
    y_test_typhoon_fji.append(y_test)
    y_pred_typhoon_fji.append(y_pred_fji)

    # Calculate root mean squared error in total
    mse_test = mean_squared_error(y_test, y_pred_fji)
    rmse_test = np.sqrt(mse_test)
    rmse_total_fji.append(rmse_test)

    # Per bin (Stratification)
    rmse_test_bin = []
    avg_error_bin = []
    for bin_num in range(num_bins)[1:]:
        if (len(y_test[bin_index_test == bin_num]) != 0 and len(y_pred_fji[bin_index_test == bin_num]) != 0):
            # Estimation of RMSE for test data per each bin
            mse_test = mean_squared_error(y_test[bin_index_test == bin_num], y_pred_fji[bin_index_test == bin_num])
            rmse_test = np.sqrt(mse_test)
            rmse_test_bin.append(rmse_test)
            # Avg error
            mean_difference = np.mean(y_test[bin_index_test == bin_num] - y_pred_fji[bin_index_test == bin_num])
            avg_error_bin.append(mean_difference)
        else:
            rmse_test_bin.append(np.nan)
            avg_error_bin.append(np.nan)

    rmse_bin_fji.append(rmse_test_bin)
    avg_error_bin_fji.append(avg_error_bin)

# RMSE & Avg error per bin
rmse_strat_fji = []
avg_error_strat_fji = []
for i in range(num_bins - 1):
    #RMSE
    test_rmse_bin = np.nanmean(np.array(rmse_bin_fji)[:,i])
    rmse_strat_fji.append(test_rmse_bin)
    #AVG error
    test_avg_bin = np.nanmean(np.array(avg_error_bin_fji)[:,i])
    avg_error_strat_fji.append(test_avg_bin)
```


```python
""" Feature importance """
# Calculate mean importance across all iterations
mean_importance = {feature: np.mean(importances) for feature, importances in feature_importance_dict.items()}

# Sort feature importance in descending order
sorted_importance = {k: v for k, v in sorted(mean_importance.items(), key=lambda item: item[1], reverse=False)}

# Plot
plt.figure(figsize=(5, 5))
sorted_values = list(sorted_importance.values())
sorted_keys = list(sorted_importance.keys())
plt.barh(range(len(sorted_importance)), sorted_values, align="center", color='skyblue')
plt.yticks(range(len(sorted_importance)), sorted_keys)
plt.xlabel("Mean Importance")
plt.title("Feature Importance \n(XGB built-in feature)")
plt.tight_layout()
plt.show()
```



![png](05.2_combined_model_adding_nonlinear_feature_files/05.2_combined_model_adding_nonlinear_feature_10_0.png)



### Special case: YASA


```python
yasa_importance = pd.DataFrame({'feature': features,
              'importance': YASA_fi[0]}).sort_values('importance')
yasa_importance
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>track_distance_root</td>
      <td>0.029431</td>
    </tr>
    <tr>
      <th>2</th>
      <td>total_houses</td>
      <td>0.034346</td>
    </tr>
    <tr>
      <th>5</th>
      <td>coast_length</td>
      <td>0.041405</td>
    </tr>
    <tr>
      <th>6</th>
      <td>with_coast</td>
      <td>0.049709</td>
    </tr>
    <tr>
      <th>7</th>
      <td>mean_elev</td>
      <td>0.064919</td>
    </tr>
    <tr>
      <th>8</th>
      <td>mean_slope</td>
      <td>0.076932</td>
    </tr>
    <tr>
      <th>1</th>
      <td>track_distance</td>
      <td>0.102674</td>
    </tr>
    <tr>
      <th>4</th>
      <td>rainfall_max_24h</td>
      <td>0.127644</td>
    </tr>
    <tr>
      <th>3</th>
      <td>rainfall_max_6h</td>
      <td>0.165285</td>
    </tr>
    <tr>
      <th>0</th>
      <td>wind_speed</td>
      <td>0.307654</td>
    </tr>
  </tbody>
</table>
</div>




```python

plt.barh(range(len(yasa_importance)), yasa_importance.importance, align="center", color='skyblue')
plt.yticks(range(len(yasa_importance)), yasa_importance.feature)
plt.xlabel("Importance")
plt.title("Feature Importance \n(XGB built-in feature) \n YASA typhoon")
plt.tight_layout()
plt.show()
```



![png](05.2_combined_model_adding_nonlinear_feature_files/05.2_combined_model_adding_nonlinear_feature_13_0.png)
