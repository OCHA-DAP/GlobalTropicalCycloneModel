```python
from pathlib import Path
import os

from climada.hazard import Centroids, TCTracks, TropCyclone
from shapely.geometry import LineString
import geopandas as gpd
import numpy as np
import pandas as pd
import xarray as xr
import matplotlib.pyplot as plt
```


```python
DEG_TO_KM = 111.1  # Convert 1 degree to km
input_dir = Path(os.getenv("STORM_DATA_DIR")) / "analysis_fji/02_model_features"
```


```python
# Just grid-land overlap
filepath = (
    input_dir
    / "02_housing_damage/output/fji_0.1_degree_grid_centroids_land_overlap_new.gpkg"
)
gdf = gpd.read_file(filepath)
# Include oceans
filepath_complete = (
    input_dir
    / "02_housing_damage/output/fji_0.1_degree_grid_centroids_new.gpkg"
)
gdf_all = gpd.read_file(filepath_complete)

# Centroids
cent = Centroids.from_geodataframe(gdf) # grid-land overlap
cent_all = Centroids.from_geodataframe(gdf_all) # include oceans
cent_all.set_dist_coast(precomputed=True)

# Load grid
grid_land_overlap = gpd.read_file(input_dir / "02_housing_damage/output/fji_0.1_degree_grid_land_overlap_new.gpkg")
grid_land_overlap["id"] = grid_land_overlap["id"].astype(int)
```

    2024-03-20 20:37:24,864 - climada.hazard.centroids.centr - WARNING - Centroids.from_geodataframe has been deprecated and will be removed in a future version. Use ther default constructor instead.
    2024-03-20 20:37:24,866 - climada.hazard.centroids.centr - WARNING - Centroids.from_geodataframe has been deprecated and will be removed in a future version. Use ther default constructor instead.


## Get typhoon data


```python
# Import list of typhoons to a dataframe
typhoons_df = pd.read_csv(input_dir / "01_windfield/typhoons.csv")
```


```python
housing_path_in = input_dir / '02_housing_damage/input'
df_housing = pd.read_csv(housing_path_in / 'fji_impact_data/processed_house_impact.csv')
```


```python
cyclones = df_housing['Cyclone Name'].unique()
intersection = typhoons_df[typhoons_df['typhoon_name'].isin(cyclones)].drop_duplicates(keep='last', subset = ['typhoon_name'])
```


```python
intersection
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>typhoon_id</th>
      <th>typhoon_name</th>
      <th>typhoon_year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>659</th>
      <td>659</td>
      <td>2010069S12188</td>
      <td>Tomas</td>
      <td>2010</td>
    </tr>
    <tr>
      <th>678</th>
      <td>678</td>
      <td>2012346S14180</td>
      <td>Evan</td>
      <td>2012</td>
    </tr>
    <tr>
      <th>715</th>
      <td>715</td>
      <td>2016041S14170</td>
      <td>Winston</td>
      <td>2016</td>
    </tr>
    <tr>
      <th>732</th>
      <td>732</td>
      <td>2018038S15172</td>
      <td>Gita</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>749</th>
      <td>749</td>
      <td>2019359S08175</td>
      <td>Sarai</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>751</th>
      <td>751</td>
      <td>2020015S12170</td>
      <td>Tino</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>759</th>
      <td>759</td>
      <td>2020092S09155</td>
      <td>Harold</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>761</th>
      <td>761</td>
      <td>2020346S13168</td>
      <td>Yasa</td>
      <td>2020</td>
    </tr>
    <tr>
      <th>769</th>
      <td>769</td>
      <td>2021029S16171</td>
      <td>Ana</td>
      <td>2021</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Download NECESARY tracks
sel_ibtracs = []
for track in intersection.typhoon_id:
    sel_ibtracs.append(TCTracks.from_ibtracs_netcdf(storm_id=track))
```

    2024-03-20 20:00:28,576 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:31,839 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:34,881 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:37,919 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:40,993 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:43,955 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:47,029 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:50,069 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:00:53,259 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.



```python
# Fix Tomas
#obs: .interp(x0,x,f(x)) gives the position of x0 in the fitting of (x,f(x))
#obs: daterange consider the track between certain intervals as discrete points instead of a continuous
tc_tracks = TCTracks()
for track in sel_ibtracs:
    tc_track = track.get_track()
    if tc_track.sid == '2010069S12188': #Tomas
        tc_track['lon'] *= -1
    tc_track.interp(
        time = pd.date_range(tc_track.time.values[0], tc_track.time.values[-1], freq="30T")
    )
    tc_tracks.append(tc_track)
```

## Define some functions


```python
def windfield_to_grid(tc, tracks, grids):
    df_windfield = pd.DataFrame()

    for intensity_sparse, event_id in zip(tc.intensity, tc.event_name):
        # Get the windfield
        windfield = intensity_sparse.toarray().flatten()
        npoints = len(windfield)
        # Get the track distance
        tc_track = tracks.get_track(track_name=event_id)
        points = gpd.points_from_xy(tc_track.lon, tc_track.lat)
        tc_track_line = LineString(points)
        DEG_TO_KM = 111.1
        tc_track_distance = grids["geometry"].apply(
            lambda point: point.distance(tc_track_line) * DEG_TO_KM
        )
        # Add to DF
        df_to_add = pd.DataFrame(
            dict(
                typhoon_name=[tc_track.name] * npoints,
                track_id=[event_id] * npoints,
                grid_point_id=grids["id"],
                wind_speed=windfield,
                track_distance=tc_track_distance,
                geometry = grids.geometry
            )
        )
        df_windfield = pd.concat([df_windfield, df_to_add], ignore_index=True)
    return df_windfield

# Define a function to calculate mean values for neighboring cells
def calculate_mean_for_neighbors(idx, gdf, buffer_size):
    row = gdf.iloc[idx]
    if row['wind_speed'] == 0:  # Check if wind_speed is 0
        buffered = row['geometry'].buffer(buffer_size)  # Adjust buffer size as needed

        # Find neighboring geometries that intersect with the buffer, excluding the current geometry
        neighbors = gdf[~gdf.geometry.equals(row['geometry']) & gdf.geometry.intersects(buffered)]

        if not neighbors.empty:
            # drop rows with 0 windspeed vals (we dont want to compute the mean while considering these cells)
            neighbors = neighbors[neighbors['wind_speed'] !=0]
            if len(neighbors) !=0:
                mean_val = neighbors['wind_speed'].mean()
            else:
                mean_val = 0
            return mean_val
    return row['wind_speed']  # Return the original value if no neighbors or wind_speed != 0

# Function to add interpolation points
def add_interpolation_points(data, num_points_between):
    new_x_list = []
    for i in range(len(data) - 1):
        start_point, end_point = data[i], data[i + 1]
        interp_x = list(np.linspace(start_point, end_point, num_points_between + 2))
        if i == 0:
            new_x_list.append(interp_x)
        elif i == (len(data) - 1):
            new_x_list.append(interp_x)
        else:
            new_x_list.append(interp_x[1:])

    new_x = np.concatenate(new_x_list)

    return new_x

# Create xarray
def adjust_tracks(forecast_df):
    track = xr.Dataset(
        data_vars={
            'max_sustained_wind': ('time', np.array(forecast_df.MeanWind.values, dtype='float32')), #0.514444 --> kn to m/s
            'environmental_pressure': ('time', forecast_df.PressureOCI.values), # I assume its enviromental pressure
            'central_pressure': ('time',forecast_df.Pressure.values),
            'lat': ('time',forecast_df.Latitude.values),
            'lon': ('time', forecast_df.Longitude.values),
            'radius_max_wind': ('time', forecast_df.RadiusMaxWinds.values),
            'radius_oci': ('time',forecast_df.RadiusOCI.values), # Works even if there is a bunch of nans. Doesnt change the windspeed values
            'time_step': ('time', forecast_df.time_step),
            'basin': ('time', np.array(forecast_df.basin, dtype='<U2'))
        },
        coords={
            'time': forecast_df.forecast_time.values,
        },
        attrs={
            'max_sustained_wind_unit': 'kn',
            'central_pressure_unit': 'mb',
            'name': name,
            'sid' : custom_sid,
            'orig_event_flag': True,
            'data_provider': 'Custom',
            'id_no' : custom_idno,
            'category': int(max(forecast_df.Category.iloc)),
        }
    )
    track = track.set_coords(['lat', 'lon'])
    return track
```

## Synthetic tracks

### Example


```python
winston_track = TCTracks.from_ibtracs_netcdf(storm_id='2016041S14170')
yasa_track = TCTracks.from_ibtracs_netcdf(storm_id='2020346S13168')

# Probabilistic events
yasa_track.equal_timestep()
yasa_track.calc_perturbed_trajectories(nb_synth_tracks=5)
ax = yasa_track.plot()
ax.set_title('YASA synthetic tracks', size=20)
plt.plot()
```

    2024-03-20 20:10:03,752 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.
    2024-03-20 20:10:07,301 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /Users/federico/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.





    []





![png](00.0_synthetic_tracks_files/00.0_synthetic_tracks_14_2.png)



### All events


```python
# Probabilistic events
tc_tracks.equal_timestep()
tc_tracks.calc_perturbed_trajectories(nb_synth_tracks=5)
```

add interpolation points


```python
tracks = TCTracks()
for i in range(len(tc_tracks.get_track())):
    # Define relevant features
    track_xarray = tc_tracks.get_track()[i]
    time_array = np.array(track_xarray.time)
    time_step_array = np.array(track_xarray.time_step)
    lat_array = np.array(track_xarray.lat)
    lon_array = np.array(track_xarray.lon)
    longs = []
    for l in lon_array:
        if l < 0:
            l+= 360
        longs.append(l)
    lon_array = np.array(longs)
    max_sustained_wind_array = np.array(track_xarray.max_sustained_wind)
    central_pressure_array = np.array(track_xarray.central_pressure)
    environmental_pressure_array = np.array(track_xarray.environmental_pressure)
    r_max_wind_array = np.array(track_xarray.radius_max_wind)
    r_oci_array = np.array(track_xarray.radius_oci)

    # Define new variables
    # Interpolate every important data
    w = max_sustained_wind_array.copy()
    t = time_array.copy()
    t_step = time_step_array.copy()
    lat = lat_array.copy()
    lon = lon_array.copy()
    cp = central_pressure_array.copy()
    ep = environmental_pressure_array.copy()
    rmax = r_max_wind_array.copy()
    roci = r_oci_array.copy()

    # Define the number of points to add between each pair of data points
    num_points_between = 2

    # Add interpolation points to regulat variables
    new_w = add_interpolation_points(w, num_points_between)
    new_t_step = add_interpolation_points(t_step, num_points_between)
    new_lat = add_interpolation_points(lat, num_points_between)
    new_lon = add_interpolation_points(lon, num_points_between)
    new_cp = add_interpolation_points(cp, num_points_between)
    new_ep = add_interpolation_points(ep, num_points_between)
    new_rmax = add_interpolation_points(rmax, num_points_between)
    new_roci = add_interpolation_points(roci, num_points_between)

    # Add interpolation points to time variables
    timestamps = np.array([date.astype('datetime64[s]').astype('int64') for date in t])# Convert to seconds
    new_t =  add_interpolation_points(timestamps, num_points_between)
    new_t = [np.datetime64(int(ts), 's') for ts in new_t]# Back to datetime format

    # Define dataframe
    df_t = pd.DataFrame({
        'MeanWind': new_w,
        'PressureOCI': new_ep,
        'Pressure': new_cp,
        'Latitude': new_lat,
        'Longitude': new_lon,
        'RadiusMaxWinds': new_rmax,
        'RadiusOCI': new_roci,
        'time_step': new_t_step,
        'basin': np.array([np.array(track_xarray.basin)[0]] * len(new_t)),
        'forecast_time': new_t,
        'Category': track_xarray.category
    })

    # Define a custom id
    custom_idno = track_xarray.id_no
    custom_sid = track_xarray.sid
    name = track_xarray.name# + ' interpolated'

    # Define track as climada likes it
    track = TCTracks()
    track.data = [adjust_tracks(df_t)]

    # Tracks modified
    tracks.append(track.get_track())
```


```python
tc_all = TropCyclone.from_tracks(
    tracks, centroids=cent_all, store_windfields=True, intensity_thres=0
)

# Create grid-level windfield
df_windfield_interpolated = windfield_to_grid(tc=tc_all, tracks=tracks, grids=gdf_all)

# Overlap
df_windfield_interpolated_overlap = df_windfield_interpolated[df_windfield_interpolated.grid_point_id.isin(gdf.id)]
```


```python
df_windfield_interpolated_overlap = df_windfield_interpolated_overlap.drop('geometry', axis=1).merge(grid_land_overlap[['id','geometry']], left_on='grid_point_id', right_on='id')
```


```python
tc_all.event_name
```




    ['2010069S12188',
     '2010069S12188_gen1',
     '2010069S12188_gen2',
     '2010069S12188_gen3',
     '2010069S12188_gen4',
     '2010069S12188_gen5',
     '2012346S14180',
     '2012346S14180_gen1',
     '2012346S14180_gen2',
     '2012346S14180_gen3',
     '2012346S14180_gen4',
     '2012346S14180_gen5',
     '2016041S14170',
     '2016041S14170_gen1',
     '2016041S14170_gen2',
     '2016041S14170_gen3',
     '2016041S14170_gen4',
     '2016041S14170_gen5',
     '2018038S15172',
     '2018038S15172_gen1',
     '2018038S15172_gen2',
     '2018038S15172_gen3',
     '2018038S15172_gen4',
     '2018038S15172_gen5',
     '2019359S08175',
     '2019359S08175_gen1',
     '2019359S08175_gen2',
     '2019359S08175_gen3',
     '2019359S08175_gen4',
     '2019359S08175_gen5',
     '2020015S12170',
     '2020015S12170_gen1',
     '2020015S12170_gen2',
     '2020015S12170_gen3',
     '2020015S12170_gen4',
     '2020015S12170_gen5',
     '2020092S09155',
     '2020092S09155_gen1',
     '2020092S09155_gen2',
     '2020092S09155_gen3',
     '2020092S09155_gen4',
     '2020092S09155_gen5',
     '2020346S13168',
     '2020346S13168_gen1',
     '2020346S13168_gen2',
     '2020346S13168_gen3',
     '2020346S13168_gen4',
     '2020346S13168_gen5',
     '2021029S16171',
     '2021029S16171_gen1',
     '2021029S16171_gen2',
     '2021029S16171_gen3',
     '2021029S16171_gen4',
     '2021029S16171_gen5']




```python
geo_synthetic_interpolated = gpd.GeoDataFrame(df_windfield_interpolated_overlap, geometry='geometry')
```

### Plots (Yasa)


```python
yasa_events = ['YASA', 'YASA_gen1', 'YASA_gen2']
geo_yasa_interpolated = geo_synthetic_interpolated[geo_synthetic_interpolated.typhoon_name.isin(yasa_events)]

fig, ax = plt.subplots(1,2, figsize=(8,5))

# Track path
tc_track = tracks.get_track()[42]
points = gpd.points_from_xy(tc_track.lon, tc_track.lat)
track_points = gpd.GeoDataFrame(geometry=points)
tc_track_line = LineString(points)
track_line = gpd.GeoDataFrame(geometry=[tc_track_line])

geo_yasa_interpolated[geo_yasa_interpolated.typhoon_name=='YASA'].plot(column='wind_speed', colormap='Reds', legend=True, ax=ax[0])
track_line.plot(ax=ax[0], color='k', label='track', linewidth=1)
ax[0].set_xlim([175,183])
ax[0].set_title('YASA mean ensamble \nWindspeed [m/s]')

# Track path
tc_track = tracks.get_track()[43]
points = gpd.points_from_xy(tc_track.lon, tc_track.lat)
track_points = gpd.GeoDataFrame(geometry=points)
tc_track_line = LineString(points)
track_line = gpd.GeoDataFrame(geometry=[tc_track_line])

geo_yasa_interpolated[geo_yasa_interpolated.typhoon_name=='YASA_gen1'].plot(column='wind_speed', colormap='Reds', legend=True, ax=ax[1])
track_line.plot(ax=ax[1], color='k', label='track', linewidth=1)
ax[1].set_xlim([175,183])
ax[1].set_title('YASA synthetic track 1 \nWindspeed [m/s]')

plt.tight_layout()
plt.show()
```



![png](00.0_synthetic_tracks_files/00.0_synthetic_tracks_24_0.png)



## Save it


```python
# Save df as a csv file
df_windfield_interpolated_overlap.to_csv(input_dir / "01_windfield/windfield_data_fji_synthetic_tracks.csv", index=False)
```
